<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>llm on deskriders</title>
    <link>/tags/llm/</link>
    <description>Recent content in llm on deskriders</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 26 Nov 2024 11:49:29 +0000</lastBuildDate><atom:link href="/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Quick Guide to Downloading DevDocs Documentation</title>
      <link>/posts/1732621769-devdocs-offline-documentation-llm/</link>
      <pubDate>Tue, 26 Nov 2024 11:49:29 +0000</pubDate>
      
      <guid>/posts/1732621769-devdocs-offline-documentation-llm/</guid>
      <description>Here is a quick way to download a copy of the documentation for any package available at https://devdocs.io
git clone https://github.com/freeCodeCamp/devdocs.git &amp;amp;&amp;amp; cd devdocs Replace the existing Dockerfile with this:
# Stage 1: Setup dependencies FROM ruby:3.3.6 as builder ENV LANG=C.UTF-8 ENV ENABLE_SERVICE_WORKER=true WORKDIR /devdocs RUN apt-get update &amp;amp;&amp;amp; \ apt-get -y install git nodejs libcurl4 &amp;amp;&amp;amp; \ gem install bundler &amp;amp;&amp;amp; \ rm -rf /var/lib/apt/lists/* COPY Gemfile Gemfile.lock Rakefile /devdocs/ RUN bundle install --system &amp;amp;&amp;amp; \ rm -rf ~/.</description>
    </item>
    
    <item>
      <title>LLM Learning Resources</title>
      <link>/posts/1729079478-llm-learning-resources/</link>
      <pubDate>Wed, 16 Oct 2024 12:51:18 +0100</pubDate>
      
      <guid>/posts/1729079478-llm-learning-resources/</guid>
      <description> Sebastian Raschka&amp;rsquo;s book &amp;ldquo;Build a Large Language Model From Scratch&amp;rdquo; Video Andrej Karpathy&amp;rsquo;s YouTube playlist on neural networks Karpathy&amp;rsquo;s NanoGPT tutorial StatQuest videos on coding a transformer from scratch Video explaining self-attention mechanism: https://youtu.be/g2BRIuln4uc GitHub repo with diagrams and implementation code: https://github.com/adalkiran/llama-nuts-and-bolts Spreadsheet-based approach: https://github.com/ianand/spreadsheets-are-all-you-need Karpathy&amp;rsquo;s llama2.c project: https://github.com/karpathy/llama2.c </description>
    </item>
    
    <item>
      <title>Setup OpenWebUI with Pinokio and run with your own models</title>
      <link>/posts/1716746252-openwebui-ollama-models/</link>
      <pubDate>Sun, 26 May 2024 18:57:32 +0100</pubDate>
      
      <guid>/posts/1716746252-openwebui-ollama-models/</guid>
      <description> Download pinokio and Setup Open WebUI Run with a single command
cd $HOME/pinokio/api/open-webui.git &amp;amp;&amp;amp; eval &amp;#34;$(conda shell.bash hook)&amp;#34; &amp;amp;&amp;amp; conda deactivate &amp;amp;&amp;amp; conda deactivate &amp;amp;&amp;amp; conda deactivate &amp;amp;&amp;amp; conda activate base &amp;amp;&amp;amp; source $HOME/pinokio/api/open-webui.git/app/backend/env/bin/activate $HOME/pinokio/api/open-webui.git/app/backend/env &amp;amp;&amp;amp; bash app/backend/s.sh </description>
    </item>
    
    <item>
      <title>Setup AiTown with Pinokio and run with your own models</title>
      <link>/posts/1714730035-aitown-ollama-models/</link>
      <pubDate>Fri, 03 May 2024 10:53:56 +0100</pubDate>
      
      <guid>/posts/1714730035-aitown-ollama-models/</guid>
      <description> Download pinokio and Setup AiTown cd $HOME/pinokio/api/aitown.git/app eval &amp;#34;$(conda shell.bash hook)&amp;#34; &amp;amp;&amp;amp; conda deactivate &amp;amp;&amp;amp; conda deactivate &amp;amp;&amp;amp; conda deactivate &amp;amp;&amp;amp; conda activate $HOME/pinokio/api/aitown.git/app/node18 Shell 1: ./convex-local-backend Shell 2: npm run dev Switch model First backup Llama3
ollama cp llama3:latest llama3-backup:latest Switch model
ollama rm llama3:latest; ollama cp openhermes:latest llama3:latest Restore llama3 from backup
ollama rm llama3:latest; ollama cp llama3-backup:latest llama3:latest Verify
ollama list </description>
    </item>
    
  </channel>
</rss>
