<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Deskriders.dev">
    <meta name="description" content="Improving developer productivity">
    <meta name="keywords" content="blog,developer">

    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Learning Speech Recognition in Python">
  <meta name="twitter:description" content="You: I would like to learn about speech_recognition module in Python
ChatGPT: The speech_recognition module is a Python library that allows you to perform speech recognition. With this library, you can easily convert spoken audio to text.
Here’s a simple example of how to use the speech_recognition module to transcribe audio from a microphone:
import speech_recognition as sr # create a Recognizer object r = sr.Recognizer() # create a Microphone object mic = sr.Microphone() # listen for audio from the microphone with mic as source: audio = r.listen(source) # transcribe the audio text = r.recognize_google(audio) print(text) This code will listen for audio from the microphone, and then transcribe the audio using Google’s speech recognition service. The transcribed text will be printed to the console.">

    <meta property="og:url" content="/posts/1671909712-python-speech-recognition-chatgpt/">
  <meta property="og:site_name" content="deskriders">
  <meta property="og:title" content="Learning Speech Recognition in Python">
  <meta property="og:description" content="You: I would like to learn about speech_recognition module in Python
ChatGPT: The speech_recognition module is a Python library that allows you to perform speech recognition. With this library, you can easily convert spoken audio to text.
Here’s a simple example of how to use the speech_recognition module to transcribe audio from a microphone:
import speech_recognition as sr # create a Recognizer object r = sr.Recognizer() # create a Microphone object mic = sr.Microphone() # listen for audio from the microphone with mic as source: audio = r.listen(source) # transcribe the audio text = r.recognize_google(audio) print(text) This code will listen for audio from the microphone, and then transcribe the audio using Google’s speech recognition service. The transcribed text will be printed to the console.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2022-12-24T19:21:52+00:00">
    <meta property="article:modified_time" content="2022-12-24T19:21:52+00:00">
    <meta property="article:tag" content="Python">
    <meta property="article:tag" content="Speech">


    
      <base href="/posts/1671909712-python-speech-recognition-chatgpt/">
    
    <title>
  Learning Speech Recognition in Python · deskriders
</title>

    
      <link rel="canonical" href="/posts/1671909712-python-speech-recognition-chatgpt/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.11.2/css/all.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="/css/coder.min.28d751104f30c16da1aa1bb04015cbe662cacfe0d1b01af4f2240ad58580069c.css" integrity="sha256-KNdREE8wwW2hqhuwQBXL5mLKz&#43;DRsBr08iQK1YWABpw=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="/css/coder-dark.min.83a2010dac9f59f943b3004cd6c4f230507ad036da635d3621401d42ec4e2835.css" integrity="sha256-g6IBDayfWflDswBM1sTyMFB60DbaY102IUAdQuxOKDU=" crossorigin="anonymous" media="screen" />
      
    

    

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.143.1">
  </head>

  
  
    
  
  <body class="colorscheme-auto">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      deskriders
    </a>
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="/posts/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="/products">Products</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="/notes/">Notes</a>
          </li>
        
      
      
    </ul>
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Learning Speech Recognition in Python</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2022-12-24T19:21:52Z'>
                December 24, 2022
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              4 minutes read
            </span>
          </div>
          <div class="categories">
  <i class="fas fa-folder"></i>
    <a href="/categories/chatgpt/">chatgpt</a></div>

          <div class="tags">
  <i class="fas fa-tag"></i>
    <a href="/tags/python/">python</a>
      <span class="separator">•</span>
    <a href="/tags/speech/">speech</a></div>

        </div>
      </header>

      <div>
        <p><strong>You:
I would like to learn about speech_recognition module in Python</strong></p>
<p>ChatGPT:
The <code>speech_recognition</code> module is a Python library that allows you to perform speech recognition. With this library, you can easily convert spoken audio to text.</p>
<p>Here&rsquo;s a simple example of how to use the <code>speech_recognition</code> module to transcribe audio from a microphone:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> speech_recognition <span style="color:#66d9ef">as</span> sr
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create a Recognizer object</span>
</span></span><span style="display:flex;"><span>r <span style="color:#f92672">=</span> sr<span style="color:#f92672">.</span>Recognizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create a Microphone object</span>
</span></span><span style="display:flex;"><span>mic <span style="color:#f92672">=</span> sr<span style="color:#f92672">.</span>Microphone()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># listen for audio from the microphone</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> mic <span style="color:#66d9ef">as</span> source:
</span></span><span style="display:flex;"><span>    audio <span style="color:#f92672">=</span> r<span style="color:#f92672">.</span>listen(source)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># transcribe the audio</span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> r<span style="color:#f92672">.</span>recognize_google(audio)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(text)
</span></span></code></pre></div><p>This code will listen for audio from the microphone, and then transcribe the audio using Google&rsquo;s speech recognition service. The transcribed text will be printed to the console.</p>
<p>You can also use the <code>speech_recognition</code> module to transcribe audio from a file or from a URL. For example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> speech_recognition <span style="color:#66d9ef">as</span> sr
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create a Recognizer object</span>
</span></span><span style="display:flex;"><span>r <span style="color:#f92672">=</span> sr<span style="color:#f92672">.</span>Recognizer()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># transcribe audio from a file</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> sr<span style="color:#f92672">.</span>AudioFile(<span style="color:#e6db74">&#34;audio.wav&#34;</span>) <span style="color:#66d9ef">as</span> source:
</span></span><span style="display:flex;"><span>    audio <span style="color:#f92672">=</span> r<span style="color:#f92672">.</span>record(source)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> r<span style="color:#f92672">.</span>recognize_google(audio)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(text)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># transcribe audio from a URL</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> sr<span style="color:#f92672">.</span>AudioFile(url) <span style="color:#66d9ef">as</span> source:
</span></span><span style="display:flex;"><span>    audio <span style="color:#f92672">=</span> r<span style="color:#f92672">.</span>record(source)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>text <span style="color:#f92672">=</span> r<span style="color:#f92672">.</span>recognize_google(audio)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(text)
</span></span></code></pre></div><p>You can also choose from a variety of different speech recognition services, such as Google Cloud Speech, IBM Watson, or Microsoft Azure.</p>
<p>I hope this helps! Let me know if you have any questions.</p>
<p><strong>You:
Do you have more information about the Recognizer module?</strong></p>
<p>ChatGPT:
Yes! The <code>Recognizer</code> class is a central component of the <code>speech_recognition</code> module. It provides various methods for recognizing spoken audio.</p>
<p>Here are some of the most commonly used methods of the <code>Recognizer</code> class:</p>
<ul>
<li>recognize_google(audio_data, language=&lsquo;en-US&rsquo;, show_all=False): This method transcribes audio using the Google Cloud Speech API. audio_data is the audio data to transcribe, and language is the language of the audio (default is &rsquo;en-US&rsquo;). If show_all is set to True, the method will return a dictionary containing all possible transcriptions.</li>
<li>recognize_sphinx(audio_data, language=&lsquo;en-US&rsquo;, show_all=False): This method transcribes audio using the CMU Sphinx speech recognition engine. audio_data is the audio data to transcribe, and language is the language of the audio (default is &rsquo;en-US&rsquo;). If show_all is set to True, the method will return a list of all possible transcriptions.</li>
<li>recognize_wit(audio_data, key, language=&lsquo;en-US&rsquo;): This method transcribes audio using the Wit.ai speech recognition service. audio_data is the audio data to transcribe, key is your Wit.ai API key, and language is the language of the audio (default is &rsquo;en-US&rsquo;).</li>
<li>recognize_bing(audio_data, key, language=&lsquo;en-US&rsquo;): This method transcribes audio using the Microsoft Bing speech recognition service. audio_data is the audio data to transcribe, key is your Bing API key, and language is the language of the audio (default is &rsquo;en-US&rsquo;).</li>
<li>recognize_api(audio_data, api_key, language=&lsquo;en-US&rsquo;): This method transcribes audio using a generic speech recognition API. audio_data is the audio data to transcribe, api_key is your API key, and language is the language of the audio (default is &rsquo;en-US&rsquo;).</li>
</ul>
<p>In addition to these methods, the <code>Recognizer</code> class also provides several other methods for working with audio data, such as <code>listen()</code> for listening to audio from a microphone or <code>record()</code> for reading audio from a file.</p>
<p>I hope this helps! Let me know if you have any other questions.</p>
<p><strong>You:
What are other interesting properties of this class?</strong></p>
<p>ChatGPT:
Here are some other interesting properties of the <code>Recognizer</code> class:</p>
<ul>
<li>energy_threshold: This property sets the minimum energy level (in dBFS) required for speech to be considered valid. By default, this value is set to 300 dBFS. You can adjust this value to fine-tune the sensitivity of the speech recognition engine.</li>
<li>dynamic_energy_threshold: This property determines whether the energy threshold should be automatically adjusted based on the volume of the input audio. If set to True, the energy threshold will be adjusted dynamically as the audio is being recorded. This can be useful for situations where the volume of the audio varies significantly.</li>
<li>pause_threshold: This property sets the minimum length of silence (in seconds) required to consider the end of a phrase. By default, this value is set to 0.8 seconds.</li>
<li>operation_timeout: This property sets the maximum amount of time (in seconds) that the speech recognition engine will wait for audio input. If no audio is received within this time, the recognition process will be terminated. By default, this value is set to 10 seconds.</li>
<li>phrase_time_limit: This property sets the maximum length of time (in seconds) that the speech recognition engine will listen for a single phrase. By default, this value is set to 10 seconds.</li>
</ul>
<p>You can use these properties to customize the behavior of the speech recognition engine to better suit your needs. For example, you might want to increase the <code>operation_timeout</code> if you&rsquo;re expecting long periods of silence in the audio, or you might want to decrease the <code>phrase_time_limit</code> if you&rsquo;re working with short phrases.</p>
<p>I hope this helps! Let me know if you have any other questions.</p>

      </div>

      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    
    
      
        © 2019 - 2026
      
       Deskriders.dev 
    
    
       · 
      Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
    
  </section>
</footer>

    </main>

    

  </body>

</html>
