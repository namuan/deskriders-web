<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Deskriders.dev">
    <meta name="description" content="Improving developer productivity">
    <meta name="keywords" content="blog,developer">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Link List :: 2024-09-30"/>
<meta name="twitter:description" content="Last 7 days (as of 2024-09-28 18:57)
https://github.com/michaelchu/optopsy/wiki * Optopsy is an open-source backtesting library for option strategies. * The library focuses on answering core questions about option strategies, rather than simulating every possible scenario. * The backtesting algorithm involves: * Evaluating option chains within specified entry and exit dates. * Grouping evaluated chains into buckets based on Days to Expiration (DTE) and delta or strike distance percent. * Constructing option strategy legs and calculating profit/loss."/>

    <meta property="og:title" content="Link List :: 2024-09-30" />
<meta property="og:description" content="Last 7 days (as of 2024-09-28 18:57)
https://github.com/michaelchu/optopsy/wiki * Optopsy is an open-source backtesting library for option strategies. * The library focuses on answering core questions about option strategies, rather than simulating every possible scenario. * The backtesting algorithm involves: * Evaluating option chains within specified entry and exit dates. * Grouping evaluated chains into buckets based on Days to Expiration (DTE) and delta or strike distance percent. * Constructing option strategy legs and calculating profit/loss." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/1727687969-linklist-2024-09-30/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-09-30T10:19:29+01:00" />
<meta property="article:modified_time" content="2024-09-30T10:19:29+01:00" />



    
      <base href="/posts/1727687969-linklist-2024-09-30/">
    
    <title>
  Link List :: 2024-09-30 · deskriders
</title>

    
      <link rel="canonical" href="/posts/1727687969-linklist-2024-09-30/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.11.2/css/all.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="/css/coder.min.28d751104f30c16da1aa1bb04015cbe662cacfe0d1b01af4f2240ad58580069c.css" integrity="sha256-KNdREE8wwW2hqhuwQBXL5mLKz&#43;DRsBr08iQK1YWABpw=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="/css/coder-dark.min.83a2010dac9f59f943b3004cd6c4f230507ad036da635d3621401d42ec4e2835.css" integrity="sha256-g6IBDayfWflDswBM1sTyMFB60DbaY102IUAdQuxOKDU=" crossorigin="anonymous" media="screen" />
      
    

    

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.110.0">
  </head>

  
  
    
  
  <body class="colorscheme-auto">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      deskriders
    </a>
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="/posts/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="/products">Products</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="/notes/">Notes</a>
          </li>
        
      
      
    </ul>
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Link List :: 2024-09-30</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2024-09-30T10:19:29&#43;01:00'>
                September 30, 2024
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              28 minutes read
            </span>
          </div>
          <div class="categories">
  <i class="fas fa-folder"></i>
    <a href="/categories/linklist/">linklist</a></div>

          <div class="tags">
  <i class="fas fa-tag"></i>
    <a href="/tags/links/">links</a></div>

        </div>
      </header>

      <div>
        <p><em>Last 7 days (as of 2024-09-28 18:57)</em></p>
<ul>
<li><strong><a href="https://github.com/michaelchu/optopsy/wiki">https://github.com/michaelchu/optopsy/wiki</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Optopsy is an open-source backtesting library for option strategies.
</span></span><span style="display:flex;"><span>* The library focuses on answering core questions about option strategies, rather than simulating every possible scenario.
</span></span><span style="display:flex;"><span>* The backtesting algorithm involves:
</span></span><span style="display:flex;"><span>    * Evaluating option chains within specified entry and exit dates.
</span></span><span style="display:flex;"><span>    * Grouping evaluated chains into buckets based on Days to Expiration (DTE) and delta or strike distance percent.
</span></span><span style="display:flex;"><span>    * Constructing option strategy legs and calculating profit/loss.
</span></span><span style="display:flex;"><span>    * Aggregating results to show average profit/loss for each bucket combination.
</span></span><span style="display:flex;"><span>* The algorithm uses bucketing and approximations for performance, so results shouldn&#39;t be the sole basis for trade decisions.
</span></span><span style="display:flex;"><span>* The library&#39;s methodology is transparently explained.
</span></span><span style="display:flex;"><span>* Contributions (pull requests, comments, suggestions) are welcome.
</span></span><span style="display:flex;"><span>* Copyright © 2020 Michael Chu.
</span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/MightyMoud/sidekick">https://github.com/MightyMoud/sidekick</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Sidekick is a CLI tool for deploying applications to a VPS, aiming for Fly.io-like simplicity.
</span></span><span style="display:flex;"><span>* **Features:**
</span></span><span style="display:flex;"><span>    * One-command VPS setup (Docker, Traefik, sOPS, age).
</span></span><span style="display:flex;"><span>    * Deploys applications from a Dockerfile.
</span></span><span style="display:flex;"><span>    * Zero-downtime deployments.
</span></span><span style="display:flex;"><span>    * High availability and load balancing.
</span></span><span style="display:flex;"><span>    * Zero-config SSL certificates.
</span></span><span style="display:flex;"><span>    * sslip.io integration.
</span></span><span style="display:flex;"><span>    * Built-in SOPS integration for secure secret management.
</span></span><span style="display:flex;"><span>* **Installation:** `brew install sidekick` (macOS) or `go install github.com/mightymoud/sidekick@latest` (Linux/Windows).
</span></span><span style="display:flex;"><span>* **Requires:** Ubuntu LTS VPS (DigitalOcean or Hetzner recommended), SSH key access.
</span></span><span style="display:flex;"><span>* **`sidekick init`:** Sets up the VPS: creates a user, disables root login, updates the system, installs Docker, Traefik, sOPS, age, and configures SSL certificates.
</span></span><span style="display:flex;"><span>* **`sidekick launch`:** Deploys an application: requires a Dockerfile and specifies the app name, exposed port, and domain (can use sslip.io).  Handles encryption of `.env` files using sOPS.
</span></span><span style="display:flex;"><span>* **`sidekick deploy`:** Deploys a new version of an application with zero downtime.  Checks for `.env` file changes and re-encrypts if necessary.
</span></span><span style="display:flex;"><span>* **`sidekick deploy preview`:** Deploys a preview environment tied to the current git commit.
</span></span><span style="display:flex;"><span>* **Roadmap:**  Includes features like docker-compose support, improved zero-downtime deploys, firewall setup, multi-VPS management, database deployment, a TUI, and CI/CD integration.
</span></span><span style="display:flex;"><span>* **License:** GPL-3.0
</span></span><span style="display:flex;"><span>* **Website:** www.sidekickdeploy.com
</span></span></code></pre></div><ul>
<li><strong><a href="https://studio.langchain.com/">https://studio.langchain.com/</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* LangGraph Studio is a desktop application for prototyping and debugging LangGraph applications locally.  Available for MacOS.
</span></span><span style="display:flex;"><span>* Offers various templates to jumpstart development:
</span></span><span style="display:flex;"><span>    * LangGraph ReAct Agent Template: A simple ReAct agent chatbot with persistent chat memory. ([langchain-ai/react-agent](https://github.com/langchain-ai/react-agent))
</span></span><span style="display:flex;"><span>    * LangGraph Data Enrichment Template:  For building data enrichment agents. ([langchain-ai/data-enrichment](https://github.com/langchain-ai/data-enrichment))
</span></span><span style="display:flex;"><span>    * LangGraph Retrieval Agent Template: A basic question-answering agent using a retriever. ([langchain-ai/retrieval-agent-template](https://github.com/langchain-ai/retrieval-agent-template))
</span></span><span style="display:flex;"><span>    * LangGraph.js Data Enrichment Template:  Similar to the above, but using LangGraph.js. ([langchain-ai/data-enrichment-js](https://github.com/langchain-ai/data-enrichment-js))
</span></span><span style="display:flex;"><span>    * LangGraph.js Retrieval Agent Template:  A basic question-answering agent using LangGraph.js and a retriever. ([langchain-ai/retrieval-agent-template-js](https://github.com/langchain-ai/retrieval-agent-template-js))
</span></span><span style="display:flex;"><span>    * LangGraph.js ReAct Agent Template: A ReAct agent using LangGraph.js. ([langchain-ai/react-agent-js](https://github.com/langchain-ai/react-agent-js))
</span></span><span style="display:flex;"><span>    * New LangGraph Project: A blank template to start a new project. ([langchain-ai/new-langgraph-project](https://github.com/langchain-ai/new-langgraph-project))
</span></span><span style="display:flex;"><span>    * New LangGraph.js Project: A blank template to start a new LangGraph.js project. ([langchain-ai/new-langgraphjs-project](https://github.com/langchain-ai/new-langgraphjs-project))
</span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/tcsenpai/multi1">https://github.com/tcsenpai/multi1</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>multi1:<span style="color:#f92672">**</span> Creates o1<span style="color:#f92672">-</span><span style="color:#66d9ef">like</span> reasoning chains <span style="color:#66d9ef">using</span> multiple AI <span style="color:#a6e22e">providers</span> (locally <span style="color:#66d9ef">and</span> remotely).
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Supports LiteLLM:<span style="color:#f92672">**</span>  Enables access <span style="color:#66d9ef">to</span> <span style="color:#ae81ff">100</span><span style="color:#f92672">+</span> providers.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span><span style="color:#66d9ef">Key</span> Features:<span style="color:#f92672">**</span> Unified interface, LiteLLM <span style="color:#66d9ef">default</span> <span style="color:#a6e22e">provider</span> (local <span style="color:#f92672">&amp;</span> remote), configurable sidebar, modular design <span style="color:#66d9ef">for</span> easy provider addition.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Supported Providers:<span style="color:#f92672">**</span> <span style="color:#a6e22e">LiteLLM</span> (local <span style="color:#f92672">&amp;</span> remote), <span style="color:#a6e22e">Ollama</span> (local), <span style="color:#a6e22e">Perplexity</span> (remote, API <span style="color:#66d9ef">key</span> required), <span style="color:#a6e22e">Groq</span> (remote, API <span style="color:#66d9ef">key</span> required).
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Reasoning Chains:<span style="color:#f92672">**</span> Improves LLM reasoning <span style="color:#66d9ef">by</span> creating dynamic Chain of Thought, prompting the model <span style="color:#66d9ef">to</span> explore multiple methods <span style="color:#66d9ef">and</span> alternative answers.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Improved Accuracy:<span style="color:#f92672">**</span> Achieves <span style="color:#f92672">~</span><span style="color:#ae81ff">70</span><span style="color:#f92672">%</span> accuracy <span style="color:#66d9ef">on</span> the Strawberry <span style="color:#a6e22e">problem</span> (compared <span style="color:#66d9ef">to</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">%</span> <span style="color:#66d9ef">for</span> Llama<span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>.<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span><span style="color:#ae81ff">70</span>b <span style="color:#66d9ef">and</span> <span style="color:#ae81ff">30</span><span style="color:#f92672">%</span> <span style="color:#66d9ef">for</span> ChatGPT<span style="color:#f92672">-</span><span style="color:#ae81ff">4</span>o without prompting).
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Open Source <span style="color:#66d9ef">and</span> Experimental:<span style="color:#f92672">**</span> Aims <span style="color:#66d9ef">to</span> inspire development of new reasoning strategies.  <span style="color:#66d9ef">Not</span> a replication of OpenAI<span style="color:#e6db74">&#39;s o1, which uses different training techniques.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* **Quickstart:** Requires Python 3, `venv` (optional), and `pip`.  Installation via `pip install -r requirements.txt`. API keys needed for some providers.  Runs using `streamlit run app/main.py`.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* **Contributing:**  Contributions welcome!  Fork the repo, create a branch, make changes, and submit a pull request.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* **Derived from g1:**  Originally developed by Benjamin Klieger.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* **License:** MIT license.
</span></span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/dena-sohrabi/There?tab=readme-ov-file">https://github.com/dena-sohrabi/There?tab=readme-ov-file</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* A native macOS menubar app to track time zones for friends, teammates, or cities.
</span></span><span style="display:flex;"><span>* Installation via Homebrew: `brew install --cask there`
</span></span><span style="display:flex;"><span>* Add people from X (Twitter), Telegram, or local photos.
</span></span><span style="display:flex;"><span>* Add cities without needing to know the time zone.
</span></span><span style="display:flex;"><span>* Supports raw UTC offsets.
</span></span><span style="display:flex;"><span>* Ultra-low resource usage (CPU and memory).
</span></span><span style="display:flex;"><span>* Built with SwiftUI.
</span></span><span style="display:flex;"><span>* Requires macOS 13+.
</span></span><span style="display:flex;"><span>* Roadmap: Widgets, time slider, auto-update, AppleScript API.
</span></span><span style="display:flex;"><span>* Contributions welcome (PRs for small fixes, issues for larger features).
</span></span><span style="display:flex;"><span>* Licensed under the MIT License.
</span></span></code></pre></div><ul>
<li>
<p><strong><a href="https://m.youtube.com/watch?v=5V6Lam8GZo4&amp;list=PLjTveVh7FakJOoY6GPZGWHHl4shhDT8iV&amp;index=1">https://m.youtube.com/watch?v=5V6Lam8GZo4&amp;list=PLjTveVh7FakJOoY6GPZGWHHl4shhDT8iV&amp;index=1</a></strong></p>
</li>
<li>
<p><strong><a href="https://x.com/marcusschiesser/status/1837080387337736217?s=12">https://x.com/marcusschiesser/status/1837080387337736217?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://plugins.jetbrains.com/plugin/20789-inlineproblems">https://plugins.jetbrains.com/plugin/20789-inlineproblems</a></strong></p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Displays compiler errors, inspections, and other problems directly within the editor, eliminating the need to switch to the Problems tool window.
</span></span><span style="display:flex;"><span>* Supports various IDEs from JetBrains, including IntelliJ IDEA, PyCharm, WebStorm, Android Studio, and others.
</span></span><span style="display:flex;"><span>* Improves code readability and reduces context switching.
</span></span><span style="display:flex;"><span>* Offers customizable settings to control the appearance and behavior of inline problem annotations.
</span></span><span style="display:flex;"><span>* Provides quick access to problem details and quick-fix options.
</span></span><span style="display:flex;"><span>* Enhances developer workflow by providing immediate feedback on code issues.
</span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/RichVarney/RealDayTrading_Wiki">https://github.com/RichVarney/RealDayTrading_Wiki</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#f92672">*</span> Downloads the <span style="color:#f92672">/</span>r<span style="color:#f92672">/</span>RealDayTrading <span style="color:#a6e22e">wiki</span> (<span style="color:#e6db74">&#34;The Damn Wiki&#34;</span>) content.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Converts the wiki content <span style="color:#66d9ef">into</span> an HTML file, including <span style="color:#66d9ef">all</span> posts <span style="color:#66d9ef">and</span> images.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Provides an EPUB <span style="color:#a6e22e">version</span> (<span style="color:#f92672">`</span>The Damn Wiki <span style="color:#f92672">-</span> Hari Seldon.epub<span style="color:#f92672">`</span>) <span style="color:#66d9ef">for</span> e<span style="color:#f92672">-</span>readers <span style="color:#66d9ef">and</span> mobile devices.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Allows easy conversion <span style="color:#66d9ef">to</span> PDF <span style="color:#66d9ef">or</span> DOCX formats.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Requires <span style="color:#f92672">`</span>beautifulsoup4<span style="color:#f92672">`</span>, <span style="color:#f92672">`</span>praw<span style="color:#f92672">`</span>, <span style="color:#66d9ef">and</span> <span style="color:#f92672">`</span>urllib3<span style="color:#f92672">`</span> libraries.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Needs a Reddit API client ID, secret, <span style="color:#66d9ef">and</span> a valid <span style="color:#66d9ef">user</span> agent <span style="color:#66d9ef">to</span> be added <span style="color:#66d9ef">to</span> <span style="color:#f92672">`</span>download_RealDayTrading_wiki.py<span style="color:#f92672">`</span>.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Outputs <span style="color:#f92672">`</span>wiki_output.html<span style="color:#f92672">`</span>, an <span style="color:#f92672">`</span>images<span style="color:#f92672">`</span> folder, <span style="color:#66d9ef">and</span> a <span style="color:#f92672">`</span>posts<span style="color:#f92672">`</span> <span style="color:#a6e22e">folder</span> (containing markdown files).
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> The HTML file can be further converted <span style="color:#66d9ef">to</span> <span style="color:#a6e22e">EPUB</span> (<span style="color:#66d9ef">using</span> Calibre), PDF, <span style="color:#66d9ef">or</span> DOCX.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Uses MIT License.
</span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/lds133/weather_landscape">https://github.com/lds133/weather_landscape</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Visualizes weather forecasts through landscape imagery, reducing reliance on raw numerical data.
</span></span><span style="display:flex;"><span>* Encodes weather information (wind, temperature, cloud cover, precipitation) within a landscape image.
</span></span><span style="display:flex;"><span>* Uses a small house in the woods as the central element, with the horizontal axis representing a 24-hour timeline.
</span></span><span style="display:flex;"><span>* Vertical axis symbolizes weather events and conditions; distance from the house indicates time.
</span></span><span style="display:flex;"><span>* Includes time markers (sunrise, sunset, noon, midnight).
</span></span><span style="display:flex;"><span>* Implemented in Python using the Pillow library and OpenWeather data.
</span></span><span style="display:flex;"><span>* Designed for a 296x128 E-Ink display.
</span></span><span style="display:flex;"><span>* Requires an OpenWeather API key (OWM_KEY in `secrets.py`).
</span></span><span style="display:flex;"><span>* Coordinates can be customized in `secrets.py`.
</span></span><span style="display:flex;"><span>* `run_test.py` for image creation testing.
</span></span><span style="display:flex;"><span>* `run_server.py` to run a server (presumably for continuous updates).
</span></span><span style="display:flex;"><span>* Hardware setup uses an ESP32 development board and a 2.9-inch E-Ink display module.
</span></span><span style="display:flex;"><span>* Currently updates the image every 15 minutes from the internet.  ESP32 MicroPython adaptation is uncertain.
</span></span><span style="display:flex;"><span>* Uses MIT license.
</span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/blixt/sol-mate-eink">https://github.com/blixt/sol-mate-eink</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#f92672">*</span> Displays weather reports <span style="color:#66d9ef">and</span> illustrations <span style="color:#66d9ef">on</span> an e<span style="color:#f92672">-</span>Paper display <span style="color:#66d9ef">using</span> a Raspberry Pi.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Uses OpenAI<span style="color:#e6db74">&#39;s Dall-E 3 for image generation (requires an API key).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Requires a Raspberry Pi 5 and a Waveshare 7.3&#34; e-Paper display (code may need adjustments for other sizes).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Uses a Python virtual environment (`venv` recommended).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Installs dependencies using `pip install -r requirements.txt`.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* `control.py` script generates and displays images; `control.py clear` clears the display.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Includes example cron job for automated updates (twice daily).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Offers a private weather API (https://github.com/blixt/sol-mate) for use, but recommends self-hosting for high volume.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Provides instructions for setup and usage.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Encourages users to report issues or contact the author on Twitter.
</span></span></span></code></pre></div><ul>
<li><strong><a href="https://old.reddit.com/r/LocalLLaMA/comments/1fl8ncf/i_trained_mistral_on_philosophy_texts_from/">https://old.reddit.com/r/LocalLLaMA/comments/1fl8ncf/i_trained_mistral_on_philosophy_texts_from/</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* A Mistral-based large language model (LLM) was fine-tuned using philosophical texts.
</span></span><span style="display:flex;"><span>* The training data comprised a diverse range of philosophical works, including those from various periods and traditions.
</span></span><span style="display:flex;"><span>* The resulting model demonstrates improved performance on tasks related to philosophy, such as question answering and text generation within a philosophical context.
</span></span><span style="display:flex;"><span>* The model exhibits a capacity for nuanced reasoning and argumentation, characteristic of philosophical discourse.
</span></span><span style="display:flex;"><span>*  The author shares the model weights, allowing others to experiment and further develop it.
</span></span><span style="display:flex;"><span>*  Potential applications include philosophical research, education, and creative writing.
</span></span><span style="display:flex;"><span>*  Limitations include potential biases inherited from the training data and the need for further evaluation and refinement.
</span></span><span style="display:flex;"><span>* The project highlights the potential of fine-tuning LLMs for specialized domains.
</span></span><span style="display:flex;"><span>* The author invites community feedback and collaboration.
</span></span><span style="display:flex;"><span>*  The project&#39;s code and data are publicly available (or will be made available).
</span></span></code></pre></div><ul>
<li>
<p><strong><a href="https://m.youtube.com/watch?v=Z5dky0oEDo8">https://m.youtube.com/watch?v=Z5dky0oEDo8</a></strong></p>
</li>
<li>
<p><strong><a href="https://x.com/__steele/status/1837300198927892619?s=12">https://x.com/__steele/status/1837300198927892619?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://x.com/quantinsider_iq/status/1837030337194643823?s=12">https://x.com/quantinsider_iq/status/1837030337194643823?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://x.com/awsbrett/status/1836735045140468141?s=12">https://x.com/awsbrett/status/1836735045140468141?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://x.com/jasonzhou1993/status/1730573628654358938?s=12">https://x.com/jasonzhou1993/status/1730573628654358938?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://x.com/dereknee/status/1833844326746792118?s=12">https://x.com/dereknee/status/1833844326746792118?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://x.com/imxiaohu/status/1828009136162050409?s=12">https://x.com/imxiaohu/status/1828009136162050409?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://github.com/koniu/recoll-webui">https://github.com/koniu/recoll-webui</a></strong></p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Recoll WebUI is a Python-based web interface for the Recoll text search tool.
</span></span><span style="display:flex;"><span>* **Requirements:** Python 2.x, Recoll 1.17+, a web browser.
</span></span><span style="display:flex;"><span>* **Download:**  Use the provided links for different Recoll versions or clone the git repository.
</span></span><span style="display:flex;"><span>* **Usage:** Can run standalone ( `webui-standalone.py` ) or via a web server (WSGI/CGI). Recoll must be configured separately.
</span></span><span style="display:flex;"><span>* **Standalone Mode:** Runs on `http://localhost:8080` by default.  Command-line arguments for address and port are available.
</span></span><span style="display:flex;"><span>* **WSGI/CGI Mode:** Example Apache2 configuration provided in the README.  Important to note the `python-path` setting to avoid import errors.  Also, the user running the daemon process is important for security.
</span></span><span style="display:flex;"><span>* **Example Upstart Script (Ubuntu):** Provided for running the Recoll indexer as a daemon.
</span></span><span style="display:flex;"><span>* **Example Crontab Entry:**  Provided to run the indexer daily.
</span></span><span style="display:flex;"><span>* **Issues:**  Addresses problems opening files when running on a server, offering solutions involving URL replacements and browser-specific workarounds (Firefox, Chrome/Chromium, Opera).  These workarounds involve configuration changes in the browser or the use of extensions.
</span></span><span style="display:flex;"><span>* **About:** A web interface for Recoll desktop search.  Uses Python, JavaScript, Smarty, and CSS.
</span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/hu-po/o">https://github.com/hu-po/o</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Project Name:<span style="color:#f92672">**</span> <span style="color:#960050;background-color:#1e0010">⚙️</span> Zero<span style="color:#f92672">-</span>Shot Autonomous Robots
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Description:<span style="color:#f92672">**</span> Uses model APIs <span style="color:#66d9ef">to</span> <span style="color:#66d9ef">create</span> a Zero<span style="color:#f92672">-</span>Shot Autonomous Robot.  Individual robot behaviors are asynchronous <span style="color:#a6e22e">nodes</span> (Python) launched via bash scripts.  A simpler alternative <span style="color:#66d9ef">to</span> ROS.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span><span style="color:#66d9ef">Key</span> Models Used:<span style="color:#f92672">**</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span> <span style="color:#a6e22e">LLM</span> (Language Language Model): text2text model <span style="color:#66d9ef">for</span> planning, reasoning, dialogue.
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span> <span style="color:#a6e22e">VLM</span> (Vision Language Model): image2text model <span style="color:#66d9ef">for</span> scene understanding, object detection.
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span> <span style="color:#a6e22e">TTS</span> (<span style="color:#66d9ef">Text</span><span style="color:#f92672">-</span><span style="color:#66d9ef">to</span><span style="color:#f92672">-</span>Speech): text2audio model <span style="color:#66d9ef">for</span> speech synthesis.
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span> <span style="color:#a6e22e">STT</span> (Speech<span style="color:#f92672">-</span><span style="color:#66d9ef">to</span><span style="color:#f92672">-</span><span style="color:#66d9ef">Text</span>): audio2text model <span style="color:#66d9ef">for</span> speech recognition.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Modules:<span style="color:#f92672">**</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span> <span style="color:#f92672">`</span>models<span style="color:#f92672">`</span>: Contains code <span style="color:#66d9ef">for</span> different model <span style="color:#a6e22e">APIs</span> (e.g., Replicate API, OpenAI API).
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span> <span style="color:#f92672">`</span>robots<span style="color:#f92672">`</span>: Contains code <span style="color:#66d9ef">for</span> different <span style="color:#a6e22e">robots</span> (e.g., HiWonder AiNex Humanoid).
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span> <span style="color:#f92672">`</span>nodes<span style="color:#f92672">`</span>: Contains code <span style="color:#66d9ef">for</span> different <span style="color:#a6e22e">nodes</span> (e.g., vision <span style="color:#66d9ef">loop</span> <span style="color:#66d9ef">using</span> a VLM).
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span> <span style="color:#f92672">`</span>params<span style="color:#f92672">`</span>: Contains code <span style="color:#66d9ef">for</span> parameters <span style="color:#66d9ef">and</span> <span style="color:#66d9ef">default</span> <span style="color:#66d9ef">values</span>.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>License:<span style="color:#f92672">**</span> MIT license
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Stars:<span style="color:#f92672">**</span> <span style="color:#ae81ff">93</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Forks:<span style="color:#f92672">**</span> <span style="color:#ae81ff">13</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Languages:<span style="color:#f92672">**</span> <span style="color:#a6e22e">Python</span> (<span style="color:#ae81ff">81</span>.<span style="color:#ae81ff">8</span><span style="color:#f92672">%</span>), <span style="color:#a6e22e">Shell</span> (<span style="color:#ae81ff">18</span>.<span style="color:#ae81ff">2</span><span style="color:#f92672">%</span>)
</span></span></code></pre></div><ul>
<li><strong><a href="https://hynek.me/articles/docker-uv/">https://hynek.me/articles/docker-uv/</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#f92672">*</span> Builds production<span style="color:#f92672">-</span>ready Python Docker containers <span style="color:#66d9ef">using</span> <span style="color:#f92672">`</span>uv<span style="color:#f92672">`</span>.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Emphasizes multi<span style="color:#f92672">-</span>stage builds <span style="color:#66d9ef">to</span> avoid shipping build tools.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Prioritizes judicious layering <span style="color:#66d9ef">for</span> faster builds, installing dependencies <span style="color:#66d9ef">before</span> the application.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Leverages <span style="color:#f92672">`</span>uv.<span style="color:#66d9ef">lock</span><span style="color:#f92672">`</span> <span style="color:#66d9ef">for</span> dependency management <span style="color:#66d9ef">and</span> caching.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Recommends byte<span style="color:#f92672">-</span>compiling Python files <span style="color:#66d9ef">for</span> faster startup.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Uses virtual environments within Docker <span style="color:#66d9ef">for</span> consistency across Python versions.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Explains the <span style="color:#66d9ef">use</span> of <span style="color:#f92672">`</span>UV_PROJECT_ENVIRONMENT<span style="color:#f92672">`</span> environment variable.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Provides a detailed Dockerfile example <span style="color:#66d9ef">using</span> <span style="color:#f92672">`</span>uv<span style="color:#f92672">`</span> <span style="color:#66d9ef">for</span> dependency <span style="color:#66d9ef">and</span> application installation.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Suggests avoiding Alpine<span style="color:#f92672">-</span>based images due <span style="color:#66d9ef">to</span> potential issues.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Includes notes <span style="color:#66d9ef">on</span> handling unpackaged applications.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Discusses the differences <span style="color:#66d9ef">between</span> <span style="color:#f92672">`</span>uv sync <span style="color:#f92672">--</span>frozen<span style="color:#f92672">`</span> <span style="color:#66d9ef">and</span> <span style="color:#f92672">`</span>uv sync <span style="color:#f92672">--</span>locked<span style="color:#f92672">`</span>.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Describes a local development workflow <span style="color:#66d9ef">using</span> Direnv <span style="color:#66d9ef">and</span> <span style="color:#f92672">`</span>.envrc<span style="color:#f92672">`</span>.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Briefly explores the possibility of two build stages but finds minimal benefit <span style="color:#66d9ef">for</span> typical web applications.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Advocates <span style="color:#66d9ef">for</span> properly packaging Python applications.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Includes a note <span style="color:#66d9ef">on</span> <span style="color:#66d9ef">using</span> <span style="color:#f92672">`--</span>locked<span style="color:#f92672">`</span> instead of <span style="color:#f92672">`--</span>frozen<span style="color:#f92672">`</span> <span style="color:#66d9ef">for</span> deployment pipelines.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Mentions resources <span style="color:#66d9ef">for</span> further Docker help.
</span></span></code></pre></div><ul>
<li><strong><a href="https://huyenchip.com/2024/07/25/genai-platform.html">https://huyenchip.com/2024/07/25/genai-platform.html</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Building a Generative AI platform involves several key components and steps.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Step 1: Enhance Context:**  Augment queries with relevant information using Retrieval-Augmented Generation (RAG).  RAG uses retrievers (term-based or embedding-based) to fetch information from external sources (documents, databases, web searches).  Consider chunking large documents for efficient processing. Hybrid search (combining term and embedding-based retrieval) is common.  Agentic RAG allows models to interact with external tools and actions (read-only or write). Query rewriting improves retrieval accuracy.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Step 2: Put in Guardrails:** Implement input and output guardrails to mitigate risks. Input guardrails prevent leaking private information to external APIs and model jailbreaking. Output guardrails evaluate response quality (checking for emptiness, malformed formats, toxicity, factual inconsistencies, sensitive information, and brand risks) and manage failures (retries, human fallback).  Consider the tradeoffs between reliability and latency.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Step 3: Add Model Router and Gateway:**  Use routers to direct queries to appropriate models based on intent or context. Gateways provide a unified interface for interacting with various models (self-hosted or third-party).
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Step 4: Reduce Latency with Cache:** Implement caching mechanisms (prompt cache, exact cache, semantic cache) to optimize performance and reduce costs.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Step 5: Add Complex Logic and Write Actions:** Incorporate complex logic and write actions to enhance system capabilities.  However, write actions increase risk.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Observability and Orchestration:**  Essential for monitoring, debugging, and managing the entire pipeline.  Includes metrics, logs, and traces.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* The architecture starts simple (query -&gt; model -&gt; response) and adds components iteratively.  Evaluation is crucial at each step.
</span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/rougier/scientific-visualization-book">https://github.com/rougier/scientific-visualization-book</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Open access book on scientific visualization using Python and Matplotlib.
</span></span><span style="display:flex;"><span>* Covers fundamental principles of Matplotlib, figure design, advanced concepts (3D, animation, optimization), and showcases.
</span></span><span style="display:flex;"><span>* Available as a PDF (95MB) on HAL and GitHub.
</span></span><span style="display:flex;"><span>* Source code and examples available on GitHub.
</span></span><span style="display:flex;"><span>* Printed edition available for purchase.
</span></span><span style="display:flex;"><span>* Options to support the author via PayPal, GitHub Sponsors, or LiberaPay.
</span></span><span style="display:flex;"><span>* Related resources: Python &amp; OpenGL for Scientific Visualization, From Python to NumPy, 100 NumPy exercises, Matplotlib cheat sheets, and a book gallery.
</span></span><span style="display:flex;"><span>* 10.6k stars and 986 forks on GitHub.
</span></span></code></pre></div><ul>
<li><strong><a href="https://mohitmishra786.github.io/UnderTheHood/">https://mohitmishra786.github.io/UnderTheHood/</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* **Machine Learning:** Covers neural networks, backpropagation, gradient descent, loss functions, regularization, ensemble learning, and deep learning concepts.  Includes topics like feature engineering, dimensionality reduction, and recurrent neural networks.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Database Systems:** Explores relational databases, transaction lifecycle, atomicity, logging (UNDO, WAL), database crash recovery, and data access methods (sequential vs. random).  Includes discussions on connection management and the limitations of mmap for databases.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **C Programming and Memory Management:** Focuses on memory management techniques, including stack and heap usage, bit manipulation, address calculation, dynamic memory allocation, struct padding, and custom buffer management.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Computer Architecture and Hardware:** Covers CPU, memory, and storage interaction, sequential vs. random access, cache optimization, DRAM operation, memory controllers, and prefetching techniques.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Advanced Machine Learning:**  Explores Machine Learning Operations (MLOps), Swin Transformer, large language model prompting, and factual association editing in graph databases.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Operating Systems:** Covers sequential access in memory and storage, multithreading (single and multi-CPU), virtual memory, page tables, memory management, and the out-of-memory killer in Linux.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Parallel Computing and CUDA:** Introduces CUDA programming for GPU acceleration and parallel execution.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Software Architecture:** Discusses monolithic vs. microservices architectures and event-driven architectures.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Frontend Development:** Covers HTTP, DNS, TypeScript, and Angular (modules, routers, components, data binding).
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **DevOps:** Briefly mentions Docker, Kubernetes, Kafka, and Quarkus.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>* **Distributed Systems:**  Covers timestamping solutions and the CAP theorem.
</span></span></code></pre></div><ul>
<li>
<p><strong><a href="https://x.com/llama_index/status/1838011309360824453?s=12">https://x.com/llama_index/status/1838011309360824453?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://github.com/ayush-agarwal-0502/Adjusting-short-straddle-Quant-bot-">https://github.com/ayush-agarwal-0502/Adjusting-short-straddle-Quant-bot-</a></strong></p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Algorithmic implementation of automated adjustment of a delta-hedged short straddle for options trading.
</span></span><span style="display:flex;"><span>* Aims to maintain profitability even if the underlying asset price moves beyond initial breakeven points.
</span></span><span style="display:flex;"><span>* Uses delta hedging to make the portfolio insensitive to market movements.
</span></span><span style="display:flex;"><span>* Automatically adjusts the straddle based on market changes to stay within the profit zone.
</span></span><span style="display:flex;"><span>* Demonstrated with a GIF showing automated trading and P/L adjustments (Note: data in GIF is imaginary).
</span></span><span style="display:flex;"><span>* Algorithm involves selling puts, delta hedging, and dynamically buying/selling calls to adjust upper and lower breakeven points.
</span></span><span style="display:flex;"><span>* Disadvantages: Potential for large losses with unrealistically fast market swings and may require additional funds for adjustments.
</span></span><span style="display:flex;"><span>* Disclaimer: For demonstration purposes only; not responsible for financial losses.
</span></span><span style="display:flex;"><span>* Skills used: Finance, Options &amp; Derivatives, Options Trading Strategies, Market Neutral Strategy, Delta Hedging, Quantitative Finance (Quant), Python.
</span></span></code></pre></div><ul>
<li>
<p><strong><a href="https://x.com/profbuehlermit/status/1838183854793711874?s=12">https://x.com/profbuehlermit/status/1838183854793711874?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://x.com/quantifiedstrat/status/1824377022539256268?s=12">https://x.com/quantifiedstrat/status/1824377022539256268?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://hangukquant.github.io/scripts/market_making/">https://hangukquant.github.io/scripts/market_making/</a></strong></p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#f92672">*</span> This tutorial demonstrates simple market making <span style="color:#66d9ef">using</span> quantpylib<span style="color:#e6db74">&#39;s gateway connectors, data feeds, and order management system (OMS).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* It uses exchanges supporting `quantpylib.gateway.master.Gateway` endpoints (e.g., Binance, Hyperliquid, Bybit).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Market making requires tracking portfolio states (orders, positions, account balance) and tick data feeds (orderbook, trades, correlated assets).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Actions are triggered by internal clocks, trade arrivals, orderbook updates, and proprietary logic.  Actions can be immediate (`onTick`) or based on stored data.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* The example uses Bybit (`exc=&#39;</span>bybit<span style="color:#e6db74">&#39;`), but can be adapted to other supported exchanges.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* `gateway` connects to the exchange, `oms` handles order/position management, and `feed` handles tick data subscription and retrieval.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* `BTC` trade feeds are used to compute `trade imbalance` as shared global data.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* `market_trade_handler` function processes trade messages (`msg = (ts, price, sz, dir)`) and updates `market_imbalance`.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* `main` function initializes `gateway`, `oms`, and subscribes to `BTC` trade feeds using `feed.add_trades_feed`.  It uses a buffer of 300 trades and registers `market_trade_handler`.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* `make` function (market making logic) uses `add_trades_feed` and `add_l2_book_feed` to subscribe to trade and orderbook ticks.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* `printer` (trade handler) and `l2_handler` (orderbook handler) process tick data.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* `l2_handler` uses orderbook data (`lob` object) to submit/cancel orders based on a defined logic:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    * Determine quote price (3rd from top of book).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    * Submit orders if no pending or tighter orders exist.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    * Cancel tighter acknowledged orders.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    * Maintain time priority for duplicate levels.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    * Cancel excess orders (more than 5 on each side).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* `l2_handler` computes various market making variables (inventory, quote imbalance, mid price, vamp, vol).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* The example shows how to use `oms.limit_order` and `oms.cancel_order` to manage orders.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* The tutorial concludes by showing example quotes on the Bybit platform.
</span></span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/autogluon/autogluon">https://github.com/autogluon/autogluon</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* AutoGluon: Fast and accurate machine learning in 3 lines of code.
</span></span><span style="display:flex;"><span>* Supports Python 3.8 - 3.11 on Linux, MacOS, and Windows.
</span></span><span style="display:flex;"><span>* Installation via pip install autogluon.  Detailed instructions (including GPU support) available in the Installation Guide.
</span></span><span style="display:flex;"><span>* Quickstart example using TabularPredictor to build ML models.
</span></span><span style="display:flex;"><span>* Handles tabular, multimodal, and time series data.
</span></span><span style="display:flex;"><span>* Offers tutorials, talks, and scientific publications.
</span></span><span style="display:flex;"><span>* Provides resources such as hands-on tutorials and scientific publications.
</span></span><span style="display:flex;"><span>* Cloud deployment options including AutoGluon Cloud, SageMaker AutoPilot, and Amazon SageMaker.
</span></span><span style="display:flex;"><span>* Licensed under the Apache 2.0 License.
</span></span><span style="display:flex;"><span>* Actively accepting code contributions.  Contributing Guide available.
</span></span><span style="display:flex;"><span>*  7.8k stars and 908 forks on GitHub.
</span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/betaacid/FastAPI-Reference-App">https://github.com/betaacid/FastAPI-Reference-App</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Reference Architecture:<span style="color:#f92672">**</span> This project provides a reference architecture <span style="color:#66d9ef">for</span> building clean, maintainable FastAPI applications.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>SWAPI Integration:<span style="color:#f92672">**</span>  Demonstrates fetching data <span style="color:#66d9ef">from</span> the SWAPI <span style="color:#a6e22e">API</span> (Star Wars API).
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span><span style="color:#66d9ef">Database</span> Storage:<span style="color:#f92672">**</span> Stores fetched <span style="color:#66d9ef">character</span> data <span style="color:#66d9ef">in</span> a PostgreSQL <span style="color:#66d9ef">database</span> <span style="color:#66d9ef">using</span> Alembic <span style="color:#66d9ef">for</span> migrations.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Modular Design:<span style="color:#f92672">**</span> Employs a layered <span style="color:#a6e22e">architecture</span> (routers, services, clients, domain logic, utils) <span style="color:#66d9ef">for</span> separation of concerns.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Comprehensive Testing:<span style="color:#f92672">**</span> Includes unit tests <span style="color:#66d9ef">with</span> mocked dependencies <span style="color:#66d9ef">and</span> a few integration tests <span style="color:#66d9ef">for</span> end<span style="color:#f92672">-</span><span style="color:#66d9ef">to</span><span style="color:#f92672">-</span>end verification.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Naming Conventions:<span style="color:#f92672">**</span>  Follows clear naming conventions <span style="color:#66d9ef">for</span> <span style="color:#a6e22e">files</span> (e.g., <span style="color:#f92672">`</span>character_service.py<span style="color:#f92672">`</span>, <span style="color:#f92672">`</span>character_router.py<span style="color:#f92672">`</span>).
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Type Safety:<span style="color:#f92672">**</span> Emphasizes <span style="color:#66d9ef">using</span> type hints <span style="color:#66d9ef">for</span> parameters <span style="color:#66d9ef">and</span> <span style="color:#66d9ef">return</span> types.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>High Test Coverage:<span style="color:#f92672">**</span> Aims <span style="color:#66d9ef">for</span> high test coverage through unit testing of individual components.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Focus <span style="color:#66d9ef">on</span> Architecture:<span style="color:#f92672">**</span> Primarily focuses <span style="color:#66d9ef">on</span> application architecture; CI<span style="color:#f92672">/</span>CD, deployment, <span style="color:#66d9ef">and</span> Docker are <span style="color:#66d9ef">not</span> covered.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Installation:<span style="color:#f92672">**</span> Requires creating a virtual environment, installing <span style="color:#a6e22e">dependencies</span> (<span style="color:#f92672">`</span>pip install <span style="color:#f92672">-</span>r requirements.txt<span style="color:#f92672">`</span>), setting environment <span style="color:#a6e22e">variables</span> (<span style="color:#66d9ef">database</span> URL), <span style="color:#66d9ef">and</span> running <span style="color:#66d9ef">database</span> <span style="color:#a6e22e">migrations</span> (<span style="color:#f92672">`</span>alembic upgrade head<span style="color:#f92672">`</span>).
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Running the App:<span style="color:#f92672">**</span> Starts <span style="color:#66d9ef">with</span> <span style="color:#f92672">`</span>uvicorn main:app <span style="color:#f92672">--</span>reload<span style="color:#f92672">`</span>.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Running Tests:<span style="color:#f92672">**</span> Uses <span style="color:#f92672">`</span>pytest<span style="color:#f92672">`</span> <span style="color:#66d9ef">for</span> running <span style="color:#66d9ef">all</span> tests, <span style="color:#f92672">`</span>pytest tests<span style="color:#f92672">/</span>unit_tests<span style="color:#f92672">/`</span> <span style="color:#66d9ef">for</span> unit tests, <span style="color:#66d9ef">and</span> <span style="color:#f92672">`</span>pytest tests<span style="color:#f92672">/</span>integration_tests<span style="color:#f92672">/`</span> <span style="color:#66d9ef">for</span> integration tests.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Technology Stack:<span style="color:#f92672">**</span> Uses FastAPI, Python, PostgreSQL, Alembic, <span style="color:#66d9ef">and</span> requests.
</span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/xlmnxp/Qocker">https://github.com/xlmnxp/Qocker</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Qocker is a user-friendly GUI application for managing Docker containers.
</span></span><span style="display:flex;"><span>* Built with PyQt5, providing an intuitive interface.
</span></span><span style="display:flex;"><span>* View Docker containers in a tree-like structure.
</span></span><span style="display:flex;"><span>* Open a terminal for any container with a double-click.
</span></span><span style="display:flex;"><span>* Start, stop, and remove containers directly from the GUI.
</span></span><span style="display:flex;"><span>* Real-time container status updates.
</span></span><span style="display:flex;"><span>* Cross-platform (Windows, macOS, and Linux).
</span></span><span style="display:flex;"><span>* Requires Python 3.6+, PyQt5, and Docker.
</span></span><span style="display:flex;"><span>* Installation via git clone, then `pip install -r requirements.txt`.
</span></span><span style="display:flex;"><span>* Run with `python3 main.py`.
</span></span><span style="display:flex;"><span>* Licensed under the GNU General Public License v3.0.
</span></span><span style="display:flex;"><span>* Contributions are welcome via Pull Requests.
</span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/EtiennePerot/open-webui-code-execution">https://github.com/EtiennePerot/open-webui-code-execution</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Provides code execution utilities for Open WebUI &amp; Ollama.
</span></span><span style="display:flex;"><span>* Uses gVisor for secure sandboxing.
</span></span><span style="display:flex;"><span>* Offers both a code execution function and a code execution tool.
</span></span><span style="display:flex;"><span>* **Code execution function:**
</span></span><span style="display:flex;"><span>    * Appears as a button under LLM-generated messages.
</span></span><span style="display:flex;"><span>    * Executes code within the message&#39;s code block.
</span></span><span style="display:flex;"><span>    * Displays output in the UI and makes it available to the LLM.
</span></span><span style="display:flex;"><span>    * Installation involves setting up Open WebUI for sandboxing, then adding the function in the Open WebUI Workspace → Functions section using `open-webui/functions/run_code.py`.
</span></span><span style="display:flex;"><span>    * Requires activating both toggles on the newly created function.
</span></span><span style="display:flex;"><span>    * Usage involves asking the model to generate code and clicking the &#34;Run code&#34; button.
</span></span><span style="display:flex;"><span>* **Code execution tool:**
</span></span><span style="display:flex;"><span>    * Allows the LLM to run code independently.
</span></span><span style="display:flex;"><span>    * Output is invisible to the user but accessible to the LLM.
</span></span><span style="display:flex;"><span>    * Installation is similar to the function, but using `open-webui/tools/run_code.py` in the Open WebUI Workspace → Tools section.
</span></span><span style="display:flex;"><span>    * Requires enabling the tool for each model in Workspace → Models.
</span></span><span style="display:flex;"><span>    * Usage involves activating the &#34;Run code&#34; toggle on the message box when prompting the model.
</span></span><span style="display:flex;"><span>* Licensed under the Apache-2.0 license.
</span></span></code></pre></div><ul>
<li>
<p><strong><a href="https://x.com/turckalicious/status/1838398701141639188?s=12">https://x.com/turckalicious/status/1838398701141639188?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://github.com/huggingface/chat-macOS">https://github.com/huggingface/chat-macOS</a></strong></p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* HuggingChat macOS is a native chat interface for macOS using open-source language models.
</span></span><span style="display:flex;"><span>* Installation involves downloading the latest `.zip` from the Releases section, unzipping, and dragging the app to the Applications folder.
</span></span><span style="display:flex;"><span>* Keyboard shortcut: ⌘ + Shift + Return
</span></span><span style="display:flex;"><span>* Feedback can be sent via email or by creating a GitHub issue.  Issues should include a clear title, description, steps to reproduce (for bugs), app version, and macOS version.
</span></span><span style="display:flex;"><span>* The project has 845 stars and 25 forks on GitHub.
</span></span><span style="display:flex;"><span>* Contributors: Cyril Zakka and Omar Sanseviero
</span></span></code></pre></div><ul>
<li><strong><a href="https://danielvanstrien.xyz/posts/post-with-code/colpali/2024-09-23-generate_colpali_dataset.html">https://danielvanstrien.xyz/posts/post-with-code/colpali/2024-09-23-generate_colpali_dataset.html</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#f92672">*</span> ColPali <span style="color:#66d9ef">is</span> a multimodal document retrieval model <span style="color:#66d9ef">using</span> a <span style="color:#a6e22e">VLM</span> (Vision Language Model) <span style="color:#66d9ef">to</span> understand <span style="color:#66d9ef">and</span> retrieve documents based <span style="color:#66d9ef">on</span> visual <span style="color:#66d9ef">and</span> textual content.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> The training data <span style="color:#66d9ef">for</span> ColPali consists of image <span style="color:#66d9ef">and</span> query pairs, allowing the model <span style="color:#66d9ef">to</span> learn the relationship <span style="color:#66d9ef">between</span> queries <span style="color:#66d9ef">and</span> images.  Negative examples can also be helpful.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> A prompt <span style="color:#66d9ef">is</span> used <span style="color:#66d9ef">to</span> generate queries <span style="color:#66d9ef">from</span> documents, focusing <span style="color:#66d9ef">on</span> creating questions relevant <span style="color:#66d9ef">to</span> the page content that a <span style="color:#66d9ef">user</span> could ask without prior knowledge of the document.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> The blog post demonstrates creating a domain<span style="color:#f92672">-</span><span style="color:#66d9ef">specific</span> dataset <span style="color:#66d9ef">for</span> ColPali <span style="color:#66d9ef">using</span> a UFO dataset sourced <span style="color:#66d9ef">from</span> internet archive PDF newsletters.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Qwen2<span style="color:#f92672">-</span>VL<span style="color:#f92672">-</span><span style="color:#ae81ff">7</span>B<span style="color:#f92672">-</span>Instruct, an open VLLM, <span style="color:#66d9ef">is</span> used <span style="color:#66d9ef">to</span> generate queries <span style="color:#66d9ef">for</span> the UFO dataset images.  The process involves <span style="color:#66d9ef">using</span> a chat template, preparing inputs <span style="color:#66d9ef">for</span> the model, <span style="color:#66d9ef">and</span> generating <span style="color:#66d9ef">text</span> responses.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> The generated queries are validated <span style="color:#66d9ef">by</span> checking <span style="color:#66d9ef">if</span> they are valid JSON <span style="color:#66d9ef">and</span> <span style="color:#66d9ef">then</span> further checked <span style="color:#66d9ef">for</span> relevance <span style="color:#66d9ef">and</span> specificity.  The prompt <span style="color:#66d9ef">is</span> iteratively refined <span style="color:#66d9ef">to</span> improve query quality.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> The process involves <span style="color:#66d9ef">using</span> the <span style="color:#f92672">`</span>transformers<span style="color:#f92672">`</span> library <span style="color:#66d9ef">and</span> functions <span style="color:#66d9ef">like</span> <span style="color:#f92672">`</span>apply_chat_template<span style="color:#f92672">`</span> <span style="color:#66d9ef">and</span> <span style="color:#f92672">`</span>process_vision_info<span style="color:#f92672">`</span> <span style="color:#66d9ef">to</span> interact <span style="color:#66d9ef">with</span> the Qwen2<span style="color:#f92672">-</span>VL model.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> The goal <span style="color:#66d9ef">is</span> <span style="color:#66d9ef">to</span> fine<span style="color:#f92672">-</span>tune ColPali <span style="color:#66d9ef">for</span> improved performance <span style="color:#66d9ef">on</span> the <span style="color:#66d9ef">specific</span> domain of UFO documents.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> The generated dataset can be used <span style="color:#66d9ef">for</span> training <span style="color:#66d9ef">or</span> fine<span style="color:#f92672">-</span>tuning ColPali models.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> The blog post discusses <span style="color:#66d9ef">using</span> Pydantic <span style="color:#66d9ef">for</span> data validation <span style="color:#66d9ef">to</span> ensure the quality of the synthetically generated data.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> The blog post mentions <span style="color:#66d9ef">using</span> <span style="color:#f92672">`</span>uv<span style="color:#f92672">`</span> <span style="color:#66d9ef">for</span> managing Python installs <span style="color:#66d9ef">and</span> <span style="color:#f92672">`</span>Polars<span style="color:#f92672">`</span> <span style="color:#66d9ef">for</span> data manipulation.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> The blog post provides code examples <span style="color:#66d9ef">for</span> loading datasets, generating queries, <span style="color:#66d9ef">and</span> validating the output.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> The blog post suggests <span style="color:#66d9ef">using</span> the <span style="color:#f92672">`</span>pdf<span style="color:#f92672">-</span><span style="color:#66d9ef">to</span><span style="color:#f92672">-</span>page<span style="color:#f92672">-</span>images<span style="color:#f92672">-</span>dataset<span style="color:#f92672">`</span> Hugging Face Space <span style="color:#66d9ef">to</span> <span style="color:#66d9ef">create</span> a dataset <span style="color:#66d9ef">from</span> PDFs.
</span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/onojk/pygame-eq-visualizer">https://github.com/onojk/pygame-eq-visualizer</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span><span style="color:#66d9ef">Real</span><span style="color:#f92672">-</span><span style="color:#66d9ef">time</span> audio visualizer:<span style="color:#f92672">**</span> Uses Pygame <span style="color:#66d9ef">and</span> PyAudio <span style="color:#66d9ef">to</span> display a dynamic representation of sound frequencies.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Live audio input:<span style="color:#f92672">**</span> Visualizes frequencies <span style="color:#66d9ef">from</span> live audio input <span style="color:#66d9ef">or</span> audio files.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Customizable:<span style="color:#f92672">**</span> Allows modification of colors, bar sizes, <span style="color:#66d9ef">and</span> animation speed.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Lightweight <span style="color:#66d9ef">and</span> simple:<span style="color:#f92672">**</span> Ideal <span style="color:#66d9ef">for</span> beginners learning audio processing <span style="color:#66d9ef">and</span> Pygame.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Prerequisites:<span style="color:#f92672">**</span> Python <span style="color:#ae81ff">3</span>.x, Pygame, PyAudio, <span style="color:#66d9ef">and</span> <span style="color:#a6e22e">PortAudio</span> (Linux).
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Installation:<span style="color:#f92672">**</span> Clone repository, install system <span style="color:#a6e22e">dependencies</span> (PortAudio <span style="color:#66d9ef">on</span> Linux), <span style="color:#66d9ef">and</span> install Python dependencies <span style="color:#66d9ef">using</span> <span style="color:#f92672">`</span>pip3 install <span style="color:#f92672">-</span>r requirements.txt<span style="color:#f92672">`</span> <span style="color:#66d9ef">or</span> <span style="color:#f92672">`</span>python3 install_requirements.py<span style="color:#f92672">`</span>.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Running:<span style="color:#f92672">**</span> Execute <span style="color:#f92672">`</span>python3 pygameeq.py<span style="color:#f92672">`</span>.  Requires a connected microphone <span style="color:#66d9ef">or</span> audio input device.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Linux Audio Input Management:<span style="color:#f92672">**</span> Uses <span style="color:#f92672">`</span>pavucontrol<span style="color:#f92672">`</span> (PulseAudio Volume Control) <span style="color:#66d9ef">to</span> manage audio input sources. Install <span style="color:#66d9ef">with</span> <span style="color:#f92672">`</span>sudo apt install pavucontrol<span style="color:#f92672">`</span>.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Customization Options:<span style="color:#f92672">**</span> Bar colors, bar size, <span style="color:#66d9ef">and</span> animation speed are customizable within the code.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Target Audience:<span style="color:#f92672">**</span> Python developers, those learning <span style="color:#66d9ef">real</span><span style="color:#f92672">-</span><span style="color:#66d9ef">time</span> audio processing, <span style="color:#66d9ef">and</span> those interested <span style="color:#66d9ef">in</span> Pygame beyond game development.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span>   <span style="color:#f92672">**</span>Lightweight <span style="color:#66d9ef">and</span> Easy <span style="color:#66d9ef">to</span> <span style="color:#66d9ef">Use</span>:<span style="color:#f92672">**</span>  Doesn<span style="color:#e6db74">&#39;t require advanced audio processing libraries.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">*   **Pygame-Centric:** Built entirely using Pygame.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">*   **License:** MIT License.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">*   **Contact:** onojk123@gmail.com
</span></span></span></code></pre></div><ul>
<li><strong><a href="https://www.startdataengineering.com/post/de-proj-step-by-step/">https://www.startdataengineering.com/post/de-proj-step-by-step/</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Introduction:<span style="color:#f92672">**</span> Guides <span style="color:#66d9ef">on</span> building a data project <span style="color:#66d9ef">from</span> scratch, addressing common challenges faced <span style="color:#66d9ef">by</span> beginners.  Provides options <span style="color:#66d9ef">for</span> interactive learning via Jupyter Notebook.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Setup:<span style="color:#f92672">**</span> Offers two options <span style="color:#66d9ef">for</span> running the project: <span style="color:#66d9ef">using</span> GitHub <span style="color:#a6e22e">Codespaces</span> (recommended) <span style="color:#66d9ef">or</span> running it locally.  Detailed steps are provided <span style="color:#66d9ef">for</span> <span style="color:#66d9ef">both</span> options, including setting up virtual environments <span style="color:#66d9ef">and</span> installing requirements.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Parts of Data Engineering:<span style="color:#f92672">**</span> Explains the <span style="color:#66d9ef">key</span> components of a data engineering project, <span style="color:#66d9ef">using</span> a three<span style="color:#f92672">-</span>hop <span style="color:#a6e22e">architecture</span> (Bronze, Silver, Gold).  Highlights the importance of defining clear requirements <span style="color:#66d9ef">before</span> <span style="color:#66d9ef">starting</span>.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Requirements:<span style="color:#f92672">**</span> Emphasizes the importance of defining precise requirements, including understanding input datasets, defining the desired output dataset, establishing <span style="color:#a6e22e">SLAs</span> (Service Level Agreements), <span style="color:#66d9ef">and</span> defining data quality checks.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Choosing Tools:<span style="color:#f92672">**</span> Recommends <span style="color:#66d9ef">using</span> Polars <span style="color:#66d9ef">for</span> data processing due <span style="color:#66d9ef">to</span> its ease of <span style="color:#66d9ef">use</span> <span style="color:#66d9ef">and</span> suitability <span style="color:#66d9ef">for</span> smaller datasets.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Data Flow Architecture:<span style="color:#f92672">**</span> Details the three<span style="color:#f92672">-</span>hop architecture:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Bronze:<span style="color:#f92672">**</span> Extracts raw data, standardizing names <span style="color:#66d9ef">and</span> data types.
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Silver:<span style="color:#f92672">**</span> Models data <span style="color:#66d9ef">for</span> analytics <span style="color:#66d9ef">using</span> a dimensional <span style="color:#a6e22e">model</span> (Kimball).  Creates dimension <span style="color:#66d9ef">tables</span> (e.g., <span style="color:#f92672">`</span>dim_customer<span style="color:#f92672">`</span>) <span style="color:#66d9ef">and</span> fact <span style="color:#66d9ef">tables</span> (e.g., <span style="color:#f92672">`</span>fct_orders<span style="color:#f92672">`</span>, <span style="color:#f92672">`</span>fct_lineitem<span style="color:#f92672">`</span>).
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Gold:<span style="color:#f92672">**</span> Creates end<span style="color:#f92672">-</span><span style="color:#66d9ef">user</span> <span style="color:#66d9ef">tables</span>.  This involves creating an Optimized Business <span style="color:#66d9ef">Table</span> (OBT) <span style="color:#66d9ef">by</span> joining fact <span style="color:#66d9ef">and</span> dimension <span style="color:#66d9ef">tables</span>, <span style="color:#66d9ef">and</span> <span style="color:#66d9ef">then</span> creating pre<span style="color:#f92672">-</span>aggregated <span style="color:#66d9ef">tables</span> tailored <span style="color:#66d9ef">to</span> <span style="color:#66d9ef">specific</span> stakeholder needs.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Data Quality Implementation:<span style="color:#f92672">**</span>  Describes implementing data quality checks, including uniqueness checks <span style="color:#66d9ef">and</span> variance checks against previous runs.  Uses SQLite <span style="color:#66d9ef">to</span> store run metadata <span style="color:#66d9ef">for</span> comparison.  Includes a flowchart illustrating the data quality <span style="color:#66d9ef">check</span> process.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Code Organization:<span style="color:#f92672">**</span> Suggests organizing code based <span style="color:#66d9ef">on</span> the multi<span style="color:#f92672">-</span>hop architecture <span style="color:#66d9ef">or</span> existing company standards.  Provides a sample folder structure <span style="color:#66d9ef">and</span> promotes code modularity <span style="color:#66d9ef">by</span> creating functions <span style="color:#66d9ef">for</span> dataset creation.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Code Testing:<span style="color:#f92672">**</span>  Includes instructions <span style="color:#66d9ef">on</span> running unit tests <span style="color:#66d9ef">using</span> <span style="color:#f92672">`</span>pytest<span style="color:#f92672">`</span>.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Next Steps:<span style="color:#f92672">**</span> Hints at future topics, such <span style="color:#66d9ef">as</span> creating base classes <span style="color:#66d9ef">for</span> code reuse.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#f92672">**</span>Conclusion:<span style="color:#f92672">**</span> Summarizes the steps involved <span style="color:#66d9ef">in</span> building a data project <span style="color:#66d9ef">and</span> encourages readers <span style="color:#66d9ef">to</span> apply the learned concepts <span style="color:#66d9ef">to</span> their own projects.
</span></span></code></pre></div><ul>
<li><strong><a href="https://blog.vespa.ai/the-rise-of-vision-driven-document-retrieval-for-rag/">https://blog.vespa.ai/the-rise-of-vision-driven-document-retrieval-for-rag/</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* ColPali is a novel document retrieval model leveraging Vision Language Models (VLMs) for Retrieval-Augmented Generation (RAG).
</span></span><span style="display:flex;"><span>* It surpasses traditional text-based retrieval by incorporating visual information (figures, tables, infographics).
</span></span><span style="display:flex;"><span>* Uses PaliGemma, a VLM with built-in OCR, to generate contextualized embeddings directly from document images.
</span></span><span style="display:flex;"><span>* Employs a &#34;late interaction&#34; similarity mechanism for efficient comparison of query and document embeddings.
</span></span><span style="display:flex;"><span>* Addresses limitations of traditional methods like time-consuming text extraction, OCR, and layout analysis.
</span></span><span style="display:flex;"><span>* Offers a &#34;What You See Is What You Search&#34; (WYSIWYS) approach.
</span></span><span style="display:flex;"><span>* Outperforms existing methods on the ViDoRe benchmark, a new benchmark for visual document retrieval.
</span></span><span style="display:flex;"><span>* Shows significant improvement on visually rich datasets.
</span></span><span style="display:flex;"><span>* Limitations include a primary focus on PDF-like documents, limited multilingual support, and potential need for domain-specific fine-tuning.
</span></span><span style="display:flex;"><span>* Simplifies RAG pipelines by directly incorporating visual information into retrieval.
</span></span><span style="display:flex;"><span>*  The ColPali architecture is considered more important than the specific VLM or training data used.  It is expected to generalize to other VLMs in the future.
</span></span><span style="display:flex;"><span>* Resources:  ColPali Paper, ColPali on GitHub, Vespa community on Slack and Discord.
</span></span></code></pre></div><ul>
<li><strong><a href="https://blog.vespa.ai/scaling-colpali-to-billions/">https://blog.vespa.ai/scaling-colpali-to-billions/</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* ColPali uses a vision-capable language model (PaliGemma) for document retrieval, surpassing traditional text-based methods.
</span></span><span style="display:flex;"><span>* It leverages contextualized vision embeddings from a VLM and a late interaction similarity function (MaxSim).
</span></span><span style="display:flex;"><span>* MaxSim compares query and document embeddings at query time, allowing interaction between image grid cell vectors and query text token vectors.
</span></span><span style="display:flex;"><span>*  ColPali generates embeddings directly from images, eliminating the need for text extraction, OCR, and layout analysis.
</span></span><span style="display:flex;"><span>*  A PDF page is represented by 1030 128-dimensional vectors (1024 image grid patches + 6 instruction tokens).
</span></span><span style="display:flex;"><span>* Query text is tokenized and represented in the same 128-dimensional vector space.
</span></span><span style="display:flex;"><span>* MaxSim is a dot product followed by max and sum reductions.  It can be expressed in Vespa&#39;s schema language and PyTorch.
</span></span><span style="display:flex;"><span>* Scaling MaxSim involves reducing query tokens, patch vectors, or vector dimensionality.
</span></span><span style="display:flex;"><span>* Hamming distance, a faster alternative to dot product, is used with binary quantization (BQ) to convert float vectors to 16-dim int8 tensors.
</span></span><span style="display:flex;"><span>*  Hamming-based MaxSim is approximately 3.5 times faster than the float dot product version.
</span></span><span style="display:flex;"><span>* Vespa&#39;s phased retrieval and ranking pipeline is used for scaling to billions of documents.
</span></span><span style="display:flex;"><span>* Approximate nearest neighbor search retrieves candidate documents, followed by MaxSim ranking.
</span></span><span style="display:flex;"><span>* Vespa supports multi-vector HNSW indexing with hamming distance for efficient nearest neighbor search.
</span></span><span style="display:flex;"><span>*  A single Vespa query performs candidate selection and ranking, avoiding large data transfers between services.
</span></span><span style="display:flex;"><span>* Query token pruning can further speed up retrieval by using a subset of query token vectors.
</span></span><span style="display:flex;"><span>*  Evaluating ColPali on the DocVQA dataset shows that the hamming-based MaxSim achieves comparable accuracy while offering significant efficiency gains (32x storage reduction and 4x speedup).
</span></span></code></pre></div><ul>
<li><strong><a href="https://blog.vespa.ai/retrieval-with-vision-language-models-colpali/">https://blog.vespa.ai/retrieval-with-vision-language-models-colpali/</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* ColPali is a new approach to PDF retrieval that uses vision language models (VLMs) to directly embed screenshots of PDF pages, eliminating the need for complex text extraction and preprocessing steps.
</span></span><span style="display:flex;"><span>* Unlike traditional text-based retrieval models, ColPali leverages the visual content of the PDF pages, including images, tables, and charts.
</span></span><span style="display:flex;"><span>* The ColPali model is based on ColBERT and PaliGemma, a powerful visual language model.  It uses multi-vector representations and late-interaction scoring for improved retrieval performance.
</span></span><span style="display:flex;"><span>* ColPali significantly outperforms traditional text-based models like BM25 and BGE-M3 on the newly introduced Visual Document Retrieval (ViDoRe) benchmark.
</span></span><span style="display:flex;"><span>* ColPali embeddings can be efficiently represented and used in Vespa using its tensor framework, enabling late-interaction scoring similar to ColBERT.  Two methods for storing ColPali embeddings in Vespa are described: one page per document and one PDF per document.
</span></span><span style="display:flex;"><span>* Vespa&#39;s tensor framework and compute engine allow for efficient representation and scoring of ColPali embeddings without custom plugins.
</span></span><span style="display:flex;"><span>* The blog post provides a Vespa schema and ranking profile example demonstrating how to integrate ColPali embeddings into a Vespa application.  It uses phased ranking with BM25 as the first phase and ColPali as the second.
</span></span><span style="display:flex;"><span>* ColPali can be combined with other retrieval models, such as using ColPali embeddings as an additional feature in a gradient boosted decision tree (GBDT) or other models.
</span></span><span style="display:flex;"><span>* A demo notebook is available showing how to use ColPali embeddings in Vespa.
</span></span><span style="display:flex;"><span>* The model can be fine-tuned for different document formats (HTML, Word, etc.) and languages.
</span></span><span style="display:flex;"><span>* ColPali handles multi-page documents by using an additional tensor dimension to represent the page.
</span></span><span style="display:flex;"><span>* The model has approximately 3 billion parameters and uses the PaliGemma 3 base model.
</span></span><span style="display:flex;"><span>* The blog post discusses interpretability of the model, allowing analysis of which parts of the page contribute most to the score.
</span></span><span style="display:flex;"><span>* The blog post addresses how to evaluate the model on custom data and how image data is stored in Vespa (base64 encoding).
</span></span><span style="display:flex;"><span>* The use of BM25 in the first phase of the ranking is justified by its efficiency and ability to serve as a strong baseline.  An alternative approach using only ColPali embeddings is also mentioned.
</span></span></code></pre></div><ul>
<li>
<p><strong><a href="https://x.com/koenbok/status/1838847016958332968?s=12">https://x.com/koenbok/status/1838847016958332968?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://x.com/ollama/status/1839007158865899651?s=12">https://x.com/ollama/status/1839007158865899651?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://x.com/ggerganov/status/1839009849805291667?s=12">https://x.com/ggerganov/status/1839009849805291667?s=12</a></strong></p>
</li>
<li>
<p><strong><a href="https://github.com/refactorfirst/RefactorFirst">https://github.com/refactorfirst/RefactorFirst</a></strong></p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-v" data-lang="v"><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#a6e22e">RefactorFirst</span> <span style="color:#66d9ef">is</span> a tool <span style="color:#66d9ef">for</span> <span style="color:#a6e22e">Java</span> codebases that identifies and prioritizes <span style="color:#a6e22e">God</span> <span style="color:#a6e22e">Classes</span>, <span style="color:#a6e22e">Highly</span> <span style="color:#a6e22e">Coupled</span> classes, and <span style="color:#a6e22e">Class</span> <span style="color:#a6e22e">Cycles</span>.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#a6e22e">It</span> uses <span style="color:#a6e22e">PMD</span> <span style="color:#66d9ef">for</span> <span style="color:#a6e22e">God</span> <span style="color:#a6e22e">Class</span> and <span style="color:#a6e22e">Coupling</span> analysis, and <span style="color:#a6e22e">JavaParser</span> <span style="color:#f92672">&amp;</span> <span style="color:#a6e22e">JGraphT</span> <span style="color:#66d9ef">for</span> cycle detection.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#a6e22e">Requires</span> <span style="color:#a6e22e">Java</span> <span style="color:#ae81ff">11</span> <span style="color:#66d9ef">or</span> newer. <span style="color:#a6e22e">Supports</span> <span style="color:#a6e22e">Java</span> <span style="color:#ae81ff">21</span>.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#a6e22e">Provides</span> analysis via command line (<span style="color:#a6e22e">HTML</span> report), <span style="color:#a6e22e">GitHub</span> <span style="color:#a6e22e">Actions</span>, <span style="color:#a6e22e">Maven</span> plugin, and <span style="color:#66d9ef">as</span> a <span style="color:#a6e22e">Maven</span> report.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#a6e22e">Generates</span> reports showing <span style="color:#a6e22e">God</span> classes, highly coupled classes, and class cycles (with cycle images).
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#a6e22e">Reports</span> prioritize classes <span style="color:#66d9ef">for</span> refactoring based on impact and effort.
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#a6e22e">Offers</span> integration with <span style="color:#a6e22e">IntelliJ</span> <span style="color:#a6e22e">Ultimate</span><span style="color:#e6db74">&#39;s Method Reference Diagram plugin for refactoring assistance.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Supports single and multi-module Maven projects with typical layouts.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Future plans include a Gradle plugin, unit test coverage integration, and incorporating more object-oriented metrics.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Uses a cost-benefit approach based on the paper &#34;Prioritizing Design Debt Investment Opportunities&#34;.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Available as a Maven plugin (version 0.5.0).
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">* Open source under the Apache-2.0 license.
</span></span></span></code></pre></div><ul>
<li><strong><a href="https://huggingface.co/blog/vlms">https://huggingface.co/blog/vlms</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-mysql" data-lang="mysql"><span style="display:flex;"><span><span style="color:#f92672">*</span> Vision Language <span style="color:#a6e22e">Models</span> (VLMs) learn <span style="color:#66d9ef">from</span> images <span style="color:#66d9ef">and</span> <span style="color:#66d9ef">text</span>, generating <span style="color:#66d9ef">text</span> outputs.  Large VLMs excel at zero<span style="color:#f92672">-</span>shot tasks <span style="color:#66d9ef">and</span> handle diverse image types.  <span style="color:#66d9ef">Use</span> cases include image captioning, visual question answering, <span style="color:#66d9ef">and</span> document understanding. Some can identify <span style="color:#66d9ef">spatial</span> properties <span style="color:#66d9ef">and</span> output bounding boxes <span style="color:#66d9ef">or</span> segmentation masks.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Open<span style="color:#f92672">-</span>source VLMs are available <span style="color:#66d9ef">on</span> the Hugging Face Hub, <span style="color:#66d9ef">with</span> <span style="color:#66d9ef">varying</span> model sizes, image resolutions, <span style="color:#66d9ef">and</span> <span style="color:#a6e22e">capabilities</span> (e.g., chat, grounding).  Models are primarily English<span style="color:#f92672">-</span>trained unless otherwise noted.  Examples include LLaVA, DeepSeek<span style="color:#f92672">-</span>VL, moondream2, CogVLM, Fuyu<span style="color:#f92672">-</span><span style="color:#ae81ff">8</span>B, KOSMOS<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>, Qwen<span style="color:#f92672">-</span>VL, <span style="color:#66d9ef">and</span> Yi<span style="color:#f92672">-</span>VL<span style="color:#f92672">-</span><span style="color:#ae81ff">34</span>B.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Selecting the <span style="color:#66d9ef">right</span> VLM involves considering factors <span style="color:#66d9ef">like</span> intended <span style="color:#66d9ef">use</span> <span style="color:#66d9ef">case</span> <span style="color:#66d9ef">and</span> performance metrics.  Leaderboards <span style="color:#66d9ef">like</span> Vision Arena <span style="color:#66d9ef">and</span> Open VLM Leaderboard rank models based <span style="color:#66d9ef">on</span> <span style="color:#66d9ef">user</span> preferences <span style="color:#66d9ef">and</span> various metrics.  The VLMEvalKit <span style="color:#66d9ef">and</span> LMMS<span style="color:#f92672">-</span>Eval toolkits facilitate benchmarking.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Benchmarks <span style="color:#66d9ef">for</span> evaluating VLMs include <span style="color:#a6e22e">MMMU</span> (comprehensive, multi<span style="color:#f92672">-</span>disciplinary), <span style="color:#a6e22e">MMBench</span> (single<span style="color:#f92672">-</span>choice questions across various skills), MathVista, AI2D, ScienceQA, <span style="color:#66d9ef">and</span> OCRBench.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> VLMs typically consist of an image encoder, an embedding projector, <span style="color:#66d9ef">and</span> a <span style="color:#66d9ef">text</span> decoder. Training methods vary; some freeze parts of the <span style="color:#a6e22e">model</span> (<span style="color:#66d9ef">like</span> LLaVA) <span style="color:#66d9ef">while</span> others train end<span style="color:#f92672">-</span><span style="color:#66d9ef">to</span><span style="color:#f92672">-</span><span style="color:#a6e22e">end</span> (<span style="color:#66d9ef">like</span> KOSMOS<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>).  Fuyu<span style="color:#f92672">-</span><span style="color:#ae81ff">8</span>B uses a different approach, feeding image patches directly <span style="color:#66d9ef">to</span> a projection layer.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> <span style="color:#66d9ef">Using</span> VLMs <span style="color:#66d9ef">with</span> <span style="color:#f92672">`</span>transformers<span style="color:#f92672">`</span> involves initializing a model <span style="color:#66d9ef">and</span> processor, processing image <span style="color:#66d9ef">and</span> <span style="color:#66d9ef">text</span> prompts, generating output <span style="color:#66d9ef">using</span> the <span style="color:#f92672">`</span>generate<span style="color:#f92672">`</span> function, <span style="color:#66d9ef">and</span> decoding the output tokens.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">*</span> Fine<span style="color:#f92672">-</span>tuning VLMs <span style="color:#66d9ef">with</span> TRL<span style="color:#e6db74">&#39;s `SFTTrainer` is supported.  An example uses the `llava-instruct` dataset for instruction fine-tuning on a LLaVA 1.5 VLM.  This requires installing the latest version of TRL.  A data collator combines text and image pairs for training.
</span></span></span></code></pre></div><ul>
<li><strong><a href="https://github.com/DrewThomasson/ebook2audiobookXTTS">https://github.com/DrewThomasson/ebook2audiobookXTTS</a></strong></li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Converts eBooks to audiobooks with chapters and metadata using Calibre and Coqui XTTS.
</span></span><span style="display:flex;"><span>* Supports optional voice cloning and multiple languages.
</span></span><span style="display:flex;"><span>* Features: eBook conversion to text, chapter splitting, high-quality text-to-speech, voice cloning, and multi-language support.
</span></span><span style="display:flex;"><span>* Requirements: Python 3.x, coqui-tts, Calibre, FFmpeg, and optionally a custom voice file.
</span></span><span style="display:flex;"><span>* Installation: Install Python, Calibre, FFmpeg, and optionally Mecab (for non-Latin languages).  Install Python packages: `pip install tts==0.21.3 pydub nltk beautifulsoup4 ebooklib tqdm`. For non-Latin languages: `python -m unidic download` and `pip install mecab mecab-python3 unidic`.
</span></span><span style="display:flex;"><span>* Supported Languages: English, Spanish, French, German, Italian, Portuguese, Polish, Turkish, Russian, Dutch, Czech, Arabic, Chinese, Japanese, Hungarian, Korean.
</span></span><span style="display:flex;"><span>* Usage:  Run via Gradio web interface (`python custom_model_ebook2audiobookXTTS_gradio.py`), basic command line (`python ebook2audiobook.py &lt;path_to_ebook_file&gt; [path_to_voice_file] [language_code]`), or custom XTTS model (`python custom_model_ebook2audiobookXTTS.py &lt;ebook_file_path&gt; &lt;target_voice_file_path&gt; &lt;language&gt; &lt;custom_model_path&gt; &lt;custom_config_path&gt; &lt;custom_vocab_path&gt;`).
</span></span><span style="display:flex;"><span>* Docker Support: Run with CPU or GPU using provided Docker commands.  Custom XTTS models can be used via Docker.
</span></span><span style="display:flex;"><span>* Supported eBook Formats: .epub, .pdf, .mobi, .txt, .html, .rtf, .chm, .lit, .pdb, .fb2, .odt, .cbr, .cbz, .prc, .lrf, .pml, .snb, .cbc, .rb, .tcr (best results with .epub or .mobi).
</span></span><span style="display:flex;"><span>* Output: Creates an .m4b file with metadata and chapters.
</span></span><span style="display:flex;"><span>* Fine-tuned XTTS models can be found on Hugging Face.
</span></span></code></pre></div><ul>
<li>
<p><strong><a href="https://old.reddit.com/r/ClaudeAI/comments/1fq57qj/launched_an_ios_app_game_from_scratch_in_1_week/">https://old.reddit.com/r/ClaudeAI/comments/1fq57qj/launched_an_ios_app_game_from_scratch_in_1_week/</a></strong></p>
</li>
<li>
<p><strong><a href="https://www.reddit.com/r/ChatGPTCoding/comments/1fpxpbc/clipanything_opensource_ai_video_editor/">https://www.reddit.com/r/ChatGPTCoding/comments/1fpxpbc/clipanything_opensource_ai_video_editor/</a></strong></p>
</li>
<li>
<p><strong><a href="https://github.com/fastapi/full-stack-fastapi-template">https://github.com/fastapi/full-stack-fastapi-template</a></strong></p>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>* Full stack modern web application template.
</span></span><span style="display:flex;"><span>* Uses FastAPI (backend), React (frontend), SQLModel, PostgreSQL, Docker, GitHub Actions.
</span></span><span style="display:flex;"><span>* Includes automatic HTTPS.
</span></span><span style="display:flex;"><span>* Features JWT authentication, secure password hashing, email-based password recovery.
</span></span><span style="display:flex;"><span>* Uses TypeScript, hooks, Vite, and Chakra UI on the frontend.
</span></span><span style="display:flex;"><span>* Includes end-to-end testing with Playwright and unit testing with Pytest.
</span></span><span style="display:flex;"><span>* Supports dark mode.
</span></span><span style="display:flex;"><span>* Uses Docker Compose for development and production.
</span></span><span style="display:flex;"><span>* Traefik is used as a reverse proxy/load balancer.
</span></span><span style="display:flex;"><span>* Deployment instructions are provided using Docker Compose and Traefik.
</span></span><span style="display:flex;"><span>* CI/CD is implemented via GitHub Actions.
</span></span><span style="display:flex;"><span>* Offers interactive API documentation.
</span></span><span style="display:flex;"><span>* Provides instructions for using a private repository.
</span></span><span style="display:flex;"><span>* Includes instructions for updating from the original template.
</span></span><span style="display:flex;"><span>* Configuration is done via .env files.
</span></span><span style="display:flex;"><span>* Includes instructions for generating secret keys.
</span></span><span style="display:flex;"><span>* Supports project generation using Copier.
</span></span><span style="display:flex;"><span>* Detailed documentation for backend, frontend, deployment, and development is available.
</span></span><span style="display:flex;"><span>* Licensed under the MIT license.
</span></span></code></pre></div>
      </div>

      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    
    
      
        © 2019 - 2025
      
       Deskriders.dev 
    
    
       · 
      Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
    
  </section>
</footer>

    </main>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-129728575-5', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>

</html>
