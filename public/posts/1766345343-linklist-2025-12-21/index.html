<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Deskriders.dev">
    <meta name="description" content="Improving developer productivity">
    <meta name="keywords" content="blog,developer">

    
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Link List :: 2025-12-21">
  <meta name="twitter:description" content="https://www.theargumentmag.com/p/you-have-18-months - The real deadline isnâ€™t when AI outsmarts us â€” itâ€™s when we stop using our own minds. - &#34;Time under tension&#34; in fitness (e.g., slower squats) builds more muscle; thinking benefits from a similar principle. - Deep thinking requires sitting with disconnected ideas to combine them into something new. - AI executives claim humans have 18 months before AI surpasses us in the workforce. - The bigger concern isnâ€™t AI taking jobs but humans degrading their own thinking abilities. - AI is already affecting deep thinking, writing, and reading skills. - Students increasingly use AI to cheat, leading to a decline in writing and critical thinking. - Writing is thinking; outsourcing it to AI empties the mind of original thought. - Reading scores are at a 32-year low, with many students unable to focus on long texts. - Even elite college students struggle with reading full books or sustained focus. - High schools have &#34;chunkified&#34; books to prepare for standardized tests, reducing deep reading. - Writing and reading are essential for deep symbolic thinking, a key skill in the modern economy. - AI is the latest threat to deep thinking, following TV, the internet, and smartphones. - Literacy restructures human thought, enabling complex ideas; its decline unwires cognitive abilities. - The skill to prioritize in the AI age: patience for long texts, holding conflicting ideas, and engaging deeply with writing. - The author prepares their child for resilience and adaptability, emphasizing continuous learning. - The author (who has ADD) uses AI as a tool to refine their own writing, not replace it. - AI can be helpful if used to clarify thoughts, not to bypass thinking entirely. https://github.com/iib0011/omni-tools - Welcome to OmniTools, a self-hosted web app offering a variety of online tools to simplify everyday tasks. - Whether you are coding, manipulating images/videos, PDFs or crunching numbers, OmniTools has you covered. - Please don&#39;t forget to star the repo to support us. - All files are processed entirely on the client side: nothing ever leaves your device. - The Docker image is super lightweight at just 28MB, making it fast to deploy and easy to self-host. - Tools include: - Image Resizer - Image Converter - Image Editor - Video Trimmer - Video Reverser - And more... - PDF Splitter - PDF Merger - PDF Editor - And more... - Case Converters - List Shuffler - Text Formatters - And more... - Date Calculators - Time Zone Converters - And more... - Generate Prime Numbers - Calculate voltage, current, or resistance - And more... - JSON Tools - CSV Tools - XML Tools - And more... https://github.com/LLmHub-dev/open-computer-use - Open Computer Use is an open-source platform that gives AI agents real computer control through browser automation, terminal access, and desktop interaction - Built for developers who want to create truly autonomous AI workflows - Unlike traditional AI assistants that only talk about tasks, Open Computer Use enables AI agents to actually perform them by: - ðŸŒ Browsing the web like a human (search, click, fill forms, extract data) - ðŸ’» Running terminal commands and managing files - ðŸ–±ï¸ Controlling desktop applications with full UI automation - ðŸ¤– Multi-agent orchestration that breaks down complex tasks - ðŸ”„ Streaming execution with real-time feedback - ðŸŽ¯ 100% open-source and self-hostable - &#34;Computer use&#34; capabilities similar to Anthropic&#39;s Claude Computer Use, but fully open-source and extensible - AI agent searching, navigating, and interacting with websites autonomously - Executing commands, managing files, and running complex workflows - Complex tasks broken down and executed by specialized agents - Human-in-the-loop control and intelligent collaboration https://github.com/hunvreus/devpush - Open-source and self-hostable alternative to Vercel, Render, Netlify, etc. - Build and deploy any app (Python, Node.js, PHP, etc.) with zero-downtime updates. - Features: real-time logs, team management, customizable environments, and domains. - Git-based deployments: Push to deploy from GitHub with zero-downtime rollouts and instant rollback. - Multi-language support: Python, Node.js, PHP, or anything that can run on Docker. - Environment management: Multiple environments with branch mapping and encrypted environment variables. - Real-time monitoring: Live and searchable build and runtime logs. - Team collaboration: Role-based access control with team invitations and permissions. - Custom domains: Support for custom domains and automatic Let&#39;s Encrypt SSL certificates. - Self-hosted and open source: Run on your own servers, MIT licensed. - Server requirements: Ubuntu 20.04&#43; or Debian 11&#43; with SSH access and sudo privileges. - Recommended DNS provider: Cloudflare. - GitHub account required for GitHub App creation. - Email provider: Resend account for login emails and invitations. - Officially supported on Ubuntu/Debian; other distros may work but are not officially supported. https://github.com/n00bvn/CanvasMCPClient - Customizable infinite canvas dashboard with integrated Model Context Protocol (MCP) server support - Open-source, self-hostable dashboard application with infinite, zoomable, and pannable canvas - Unified interface for interacting with multiple MCP servers through a flexible, widget-based system - Features: - ðŸŽ¨ Infinite Canvas: Organize workspace spatially with unlimited zoom and pan capabilities - ðŸ§© Modular Widgets: 12&#43; pre-built widgets or create custom components - ðŸ› ï¸ No-code Widget Builder: Create widgets without coding - ðŸ¤– MCP Integration: Connect to multiple MCP servers using FastMCP library - ðŸ”Œ AI-Powered: Configure multiple AI providers (OpenAI, Anthropic, Ollama, Google) - ðŸŽ­ Template System: Save and share widget and dashboard configurations - ðŸ³ Easy Deployment: One-command Docker setup or manual installation - ðŸ”’ Privacy-First: All data stays on your infrastructure, no external dependencies https://www.ultracite.ai/ - Highly opinionated, zero-configuration linter and formatter - Ultracite is a preset for Biome, designed for consistent and type-safe code without configuration - Why choose Ultracite? - Zero-config by design - Hundreds of rules for JavaScript/TypeScript optimization - Customizable when needed - Designed for humans and AI - Ensures consistent code style and quality - Reduces code review friction - Agent integration for AI workflows - Editor configuration generation - Configurable spec with zero-config Biome - MCP Support for remote linting/formatting - VS Code output panel integration - Works with popular IDEs and AI agents https://github.com/AgiFlow/aicode-toolkit - Enforce AI coding agents to follow team conventions and existing practices - Centralized, shareable location with hierarchical inheritance for team conventions - Encode best practices in YAML instead of plain-text documentation - Works across multiple AI tools (Claude Code, Cursor, Gemini CLI) https://www.reddit.com/r/LocalLLaMA/comments/1o6zg97/update_qwen3vl_cookbooks_coming_recognition/ - Qwen3-VL cookbooks coming soon, covering recognition, localization, document parsing, video understanding, and key information extraction. - Cookbooks for various capabilities: - **Omni Recognition**: Identify animals, plants, people, scenic spots, cars, merchandise, and more. - **Powerful Document Parsing**: Parse text, layout position info, and Qwen HTML format. - **Precise Object Grounding**: Supports relative position coordinates (boxes/points) for positioning and labeling. - **General OCR &amp; Key Info Extraction**: Strong text recognition in natural scenes/multiple languages; supports diverse key info extraction. - **Video Understanding**: Better video OCR, long video understanding, and video grounding. - **Mobile Agent**: Locate and think for mobile phone control. - **Computer-Use Agent**: Locate and think for controlling computers and the web. - **3D Grounding**: Accurate 3D bounding boxes for indoor/outdoor objects. - **Thinking with Images**: Uses `image_zoom_in_tool` and `search_tool` for fine-grained visual detail comprehension. - **MultiModal Coding**: Generate accurate code based on multimodal info. - **Long Document Understanding**: Rigorous semantic comprehension of ultra-long documents. - **Spatial Understanding**: See, understand, and reason about spatial information. https://github.com/thomasschafer/scooter - Interactive find-and-replace terminal UI app. - Recursively searches files in the current directory by default. https://www.reddit.com/r/mcp/comments/1oc7b90/interactive_brokers_mcp/ - Interactive Brokers MCP https://old.reddit.com/r/LocalLLaMA/comments/1obn0q7/the_innovations_in_deepseek_ocr/ - DeepSeek released a new paper called &#34;DeepSeek OCR,&#34; which is more significant than a typical OCR model. - Traditional vision LLM tokens were inefficient, often requiring more space than text tokens (e.g., 10k words â†’ 15k tokens or 30k-60k visual tokens). - DeepSeek achieved 10x better compression with vision tokens compared to text tokens (10k words â†’ 1,500 compressed visual tokens). - This aligns with human memory, where visual recall (e.g., book page layout) is often more efficient than textual recall. - Unclear how this affects LLM reasoningâ€”whether compressed visual tokens impact articulation or cognitive performance. - Potential to expand context sizes significantly, especially when combined with sparse attention techniques. - Google (Gemini) may already use similar methods, explaining its large context size and OCR efficiency, but keeps it secret. - DeepSeek open-sourced their model, allowing public exploration and experimentation. - Even with potential trade-offs (e.g., lossy attention), this could enable frontier LLMs with 10-20 million token context windows. - Practical applications: - Storing entire company documents in a prompt preamble for efficient querying. - Caching entire codebases and updating them via git diffs. - Analogy to physicist Hans Bethe, who memorized vast data for seamless problem-solving. - This approach could expand working memory capacity by 10x or more. https://github.com/hauxir/macos-live-screensaver - A macOS screensaver that plays live video streams. - Supports YouTube videos and direct HLS streams. - Also available: Android TV Live Screensaver. - Turn any live stream into your screensaver/lockscreen. https://github.com/requie/LLMSecurityGuide - Comprehensive guide to offensive and defensive security for Large Language Models and Agentic AI Systems https://github.com/youkchansim/tree-of-thought - Systematic problem-solving framework for Claude Code CLI based on Princeton NLP research - Tree of Thought (ToT) enables AI to solve complex problems through systematic exploration of solution spaces - Generates multiple solution paths at each decision point - Evaluates and compares different approaches systematically - Backtracks and explores alternatives when paths don&#39;t work - Finds optimal solutions through structured search https://github.com/huntoai/phishing-ai-agent - AI agent designed to identify vulnerable employees susceptible to phishing attacks - Uses public data sources to gather information and assess vulnerability https://github.com/ArmanShirzad/fastapi-production-template - Production-ready FastAPI template with Docker, CI/CD, observability, and one-click deployment to Render or Koyeb - UV package management for faster, more reliable builds - FastAPI with Python 3.12 https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the - OpenAI released gpt-oss-120b and gpt-oss-20b, their first open-weight models since GPT-2 in 2019. - These models can run locally with optimizations like MXFP4 quantization. - The architecture builds on the transformer design but includes several modern tweaks. - Key changes from GPT-2: - Removal of dropout (no longer needed due to single-epoch training). - Replacement of absolute positional embeddings with RoPE (Rotary Position Embedding). - Swish/SwiGLU activation functions replace GELU for computational efficiency. - Mixture-of-Experts (MoE) replaces single feed-forward modules for sparse activation. - Grouped Query Attention (GQA) replaces Multi-Head Attention (MHA) for efficiency. - Sliding window attention alternates with full-context layers to reduce compute costs. - RMSNorm replaces LayerNorm for cheaper normalization. - Comparison with Qwen3: - gpt-oss is wider (larger embedding dimensions) while Qwen3 is deeper (more transformer blocks). - gpt-oss uses fewer, larger experts (32 vs. 128 in Qwen3) but activates fewer per token (4 vs. 8). - Both use GQA, but gpt-oss adds sliding window attention. - gpt-oss includes attention bias units (rare in modern models) and attention sinks (learned per-head bias logits). - Training details: - Trained on mostly English, text-only datasets with a focus on STEM, coding, and general knowledge. - Includes supervised fine-tuning and reinforcement learning stages. - 2.1 million H100-hours for gpt-oss-120b (10x less for gpt-oss-20b). - Reasoning capabilities: - Supports adjustable reasoning effort (low/medium/high) via system prompts. - Designed for tool use, potentially reducing reliance on memorization. - MXFP4 optimization: - Enables single-GPU inference (80GB H100 for 120B model, 16GB VRAM for 20B model). - Requires RTX 50-series or newer for full efficiency (older GPUs supported with higher memory usage). - Benchmarks: - Competitive with proprietary models like GPT-5 and Qwen3 in reasoning tasks. - Not yet listed on LM Arena leaderboard; early users report high hallucination rates. - Licensing: - Apache 2.0 license (open-weight, not full open-source). - Allows commercial use and distillation into other models. - GPT-5 context: - Released shortly after gpt-oss, showing OpenAIâ€™s open models are close to proprietary performance. - Additional notes: - Attention sinks stabilize long-context scenarios without modifying input tokens. - Sliding window attention (128 tokens) is smaller than in other models (e.g., Gemmaâ€™s 1024 tokens). - No base models released (only instruction-tuned versions), unlike Qwen3. https://github.com/theaniketgiri/create-llm - CLI tool for scaffolding LLM creation and training - Create production-ready LLM training projects in seconds - Similar to create-next-app but for training custom language models https://github.com/kchander/magix-extension - AI-Powered Website Customization in Your Browser - Magix is a powerful Chrome extension that lets you modify any website using natural language - No coding required - just describe what you want, and watch as AI generates and applies the changes in real-time - Think of it as ChatGPT meets Tampermonkey - the conversational intelligence of AI combined with the power of custom scripts - ðŸŽ¨ Customize Any Site - Dark mode for sites that don&#39;t have it, remove annoying elements, add missing features - ðŸ’¬ Chat-Based Interface - Iteratively improve your modifications through conversation - ðŸ”’ Privacy-First - Uses your own API keys, no data collection - ðŸŒ Community Sharing - Discover and install modifications made by others - âš¡ Instant Results - See changes applied in real-time https://github.com/DeutscheKI/jetbrains-mini-agent - OfflineAI is a privacy-optimized LLM coding agent. - Works best with `Qwen3-Coder-30B-A3B-Instruct-UD-Q4_K_XL.gguf` on RTX 3090 or higher. - Activate by clicking in source code and pressing `Ctrl&#43;Alt&#43;Shift&#43;H` (for Help). - OfflineAI Chat window opens; type a task and start with `Ctrl&#43;Return`. - Cancel tasks with the &#34;Reset Chat History&#34; button (top right). - Agent never modifies files directly; shows diffs in the IDE. https://github.com/swannysec/lessons-from-github - A compilation of professional principles and lessons learned from nearly a decade defending the internet from baddies at GitHub - Practical Guidance for Security and Engineering Professionals https://eugeneyan.com/writing/principal/ - Different principals have different strengths: deep expertise, horizontal influence, technical leadership, or cross-org alignment. - Principals should remain hands-on, but their core role shifts to vision, design, sponsorship, and enabling others. - Principals act as part-time PMs, engineers, designers, and moreâ€”nothing is outside their scope. - More communication, influence, and cross-team collaboration are required; avoid shipping org charts to customers. - Being right isnâ€™t enoughâ€”you must convince others to act, build momentum, and secure sponsorship. - Principals often teach the org to value new ideas, even if success rates are low (e.g., 3 out of 10 pitches). - Focus on work that wonâ€™t happen without youâ€”prototype, align orgs, or define long-term vision. - Connecting teams, reusing solutions, and identifying growth opportunities can be more valuable than doing the work yourself. - Scale impact by coaching and mentoring others; set aside time for office hours or regular syncs. - Transition ownership to othersâ€”let them drive direction, even if their approach differs from yours. - Create space in meetings for others to contribute; avoid dominating discussions. - Silence in meetings can signal trustâ€”if the team is on track, step back. - In exec meetings, focus on meaningful questions and decisions only they can make. - Guard your timeâ€”avoid becoming the &#34;go-to&#34; person for every meeting or review. - If you canâ€™t justify why a project needs a principal, reconsider its priority. - Leverage organizational privilege to improve outcomes with minimal effort. - Be mindful of your influenceâ€”casual comments may be overinterpreted. - Always explain the &#34;why&#34; behind your decisions to prevent blind adherence. - Stay connected with teams through reviews, demos, or informal interactions. - Help teams see the bigger picture beyond day-to-day delivery. - Balance big-picture thinking with pragmatic, local solutions. - Decline low-quality feedback requests if you lack sufficient context. - Engage with internsâ€”early check-ins and meaningful projects can be transformative. - Remove yourself from the critical path; empower others to take ownership. - If promoted, continue what made you successfulâ€”engage with peers and define your focus. - Autonomy comes with responsibilityâ€”choose high-leverage problems, not just what you prefer. - Define your charter: owner (deep involvement), sponsor (alignment/drive), or consultant (guidance). - Build a peer networkâ€”being a principal can feel isolating. - Prioritize personal growth and well-being to avoid burnout. - Keep learningâ€”timebox stagnant projects and seek external knowledge (papers, prototypes). https://github.com/gruquilla/FinAPy - Single-stock analysis using Python and local machine learning/ AI tools (Ollama, LSTM). CC BY-NC-SA. https://github.com/relikd/Memmon - Memmon restores window positions on external monitors for Mac. - Limitations: - Restores windows in other spaces only if the space is activated. - Untested support for &#34;Displays have separate Spaces&#34; (issue #5). - Requires macOS 10.10 or newer. https://github.com/Ranteck/PyStrict-strict-python - Maximum strictness for Python projects, inspired by TypeScriptâ€™s --strict mode. - Provides a `pyproject.toml` template and tooling configuration. https://github.com/louivers/spacepigeon - SpacePigeon is a native macOS app (powered by Hammerspoon) that lets you define workspaces â€” which apps open, which desktop spaces they go to, and how windows are arranged. - Effortlessly transition between workflows. SpacePigeon instantly orchestrates your applications, windows, and displays into the perfect environment for any task with a single click or hotkey. - ðŸš€ One-Click Setup: Installs everything automatically. If you don&#39;t have Hammerspoon, SpacePigeon will download and install it for you. - ðŸŽ¨ Visual Configuration: A full native UI to manage your workspaces. No need to touch Lua code manually. - ðŸ–¥ Multi-Monitor Support: Configure spaces and app layouts for both your Main and Secondary monitors. https://github.com/devtoolcss/chrome-inspector-mcp - Provides agents with DOM Elements, CSS Rules, and Computed Style tools not available in chrome-devtools-mcp https://github.com/siddharthvaddem/openscreen - OpenScreen is a free, open-source alternative to Screen Studio for creating product demos and walkthroughs. - Simpler than Screen Studio, covering basic features without a $29/month cost. - Not a 1:1 clone; supports essential functionality for users who want control and no fees. - 100% free for personal and commercial use; modify and distribute as needed (attribution appreciated). - Features: - Record full screen or specific apps. - Manual zooms with customizable depth levels. - Adjust zoom duration and position. - Crop recordings to hide parts. - Background options: wallpapers, solid colors, gradients, or custom images. - Motion blur for smoother transitions. - Add annotations (text, arrows, images). - Trim video clips. - Export in various aspect ratios and resolutions. https://brooker.co.za/blog/2025/11/20/what-now.html - Cloudflareâ€™s November 18 outage postmortem sparked discussions about error handling, focusing on Rustâ€™s `Result` and `unwrap`. - `Result` in Rust can hold a success or error; `unwrap` extracts the success or crashes the program (similar to `assert`). - Debate on `assert` in production misses the pointâ€”error handling is a global system property, not local. - Error handling game: Decide if crashing (âœ…) or not (âŒ) is appropriate, with justifications provided. - Three principles guide error handling decisions: - **Correlated failures**: If failures are uncorrelated, crashing simplifies the system; if correlated, design to reject errors and continue. - **Higher-layer handling**: Traditional architectures handle low error rates; fine-grained (e.g., serverless) handle higher rates, making crashing more acceptable. - **Meaningful continuation**: Some systems (e.g., databases) must crash to avoid state corruption; others can use last-known-good versions. - Error handling must be designed globally from the start; local decisions are insufficient. - Blast radius reduction (e.g., cell-based architectures, shuffle sharding) limits damage from errors. - `panic` (like `unwrap`) is treated as a crash here; Rustâ€™s explicitness is better than Câ€™s silent failures. - Suggestions: Rename `unwrap` to `or_panic` or enforce justifications via lints (e.g., `clippy`). https://github.com/vijaykumarpeta/yt-comments-extractor - Powerful desktop application for extracting and filtering YouTube comments with advanced spam detection - Built for researchers, data analysts, content creators, and anyone needing clean, actionable comment data - Connects to YouTube Data API to fetch comments from any public video https://github.com/gadievron/raptor - Autonomous Offensive/Defensive Research Framework - RAPTOR: Recursive Autonomous Penetration Testing and Observation Robot - Features: - Scans code with Semgrep and CodeQL - Fuzzes binaries with AFL - Analyzes vulnerabilities using LLM reasoning - Generates proof-of-concepts - Patches vulnerabilities - FFmpeg-specific patching - OSS Forensics for GitHub investigations - Agentic Skills Engine (SecOpsAgentKit) - Structured reporting https://github.com/remorses/playwriter - Like Playwright MCP but via extension - 90% less context window - 10x more capable (full playwright API) https://github.com/breethomas/pm-coding-guardrails - Coding standards and quality gates for product managers working with AI assistants in shared codebases - PMs using AI to code face unique challenges: shipping value quickly without creating cleanup work for engineering teams https://github.com/trimstray/nginx-admins-handbook - My notes on NGINX administration basics, tips &amp; tricks, caveats, and gotchas. https://github.com/bullmeza/screen.vision - Try for free at [screen.vision](https://screen.vision) - Demo video: [Screen.Vision.Demo.mp4](https://screen.vision/demo) - **How It Works:** - Describe your goal (e.g., &#34;Set up 2FA on Google&#34; or &#34;Configure Git SSH keys&#34;) - Share screen via browserâ€™s built-in screen sharing - AI analyzes screen state using vision language models - Receive one instruction at a time (e.g., &#34;Click the blue Settings button&#34;) - Automatic progress detection â€“ Next step provided after screen changes">

    <meta property="og:url" content="/posts/1766345343-linklist-2025-12-21/">
  <meta property="og:site_name" content="deskriders">
  <meta property="og:title" content="Link List :: 2025-12-21">
  <meta property="og:description" content="https://www.theargumentmag.com/p/you-have-18-months - The real deadline isnâ€™t when AI outsmarts us â€” itâ€™s when we stop using our own minds. - &#34;Time under tension&#34; in fitness (e.g., slower squats) builds more muscle; thinking benefits from a similar principle. - Deep thinking requires sitting with disconnected ideas to combine them into something new. - AI executives claim humans have 18 months before AI surpasses us in the workforce. - The bigger concern isnâ€™t AI taking jobs but humans degrading their own thinking abilities. - AI is already affecting deep thinking, writing, and reading skills. - Students increasingly use AI to cheat, leading to a decline in writing and critical thinking. - Writing is thinking; outsourcing it to AI empties the mind of original thought. - Reading scores are at a 32-year low, with many students unable to focus on long texts. - Even elite college students struggle with reading full books or sustained focus. - High schools have &#34;chunkified&#34; books to prepare for standardized tests, reducing deep reading. - Writing and reading are essential for deep symbolic thinking, a key skill in the modern economy. - AI is the latest threat to deep thinking, following TV, the internet, and smartphones. - Literacy restructures human thought, enabling complex ideas; its decline unwires cognitive abilities. - The skill to prioritize in the AI age: patience for long texts, holding conflicting ideas, and engaging deeply with writing. - The author prepares their child for resilience and adaptability, emphasizing continuous learning. - The author (who has ADD) uses AI as a tool to refine their own writing, not replace it. - AI can be helpful if used to clarify thoughts, not to bypass thinking entirely. https://github.com/iib0011/omni-tools - Welcome to OmniTools, a self-hosted web app offering a variety of online tools to simplify everyday tasks. - Whether you are coding, manipulating images/videos, PDFs or crunching numbers, OmniTools has you covered. - Please don&#39;t forget to star the repo to support us. - All files are processed entirely on the client side: nothing ever leaves your device. - The Docker image is super lightweight at just 28MB, making it fast to deploy and easy to self-host. - Tools include: - Image Resizer - Image Converter - Image Editor - Video Trimmer - Video Reverser - And more... - PDF Splitter - PDF Merger - PDF Editor - And more... - Case Converters - List Shuffler - Text Formatters - And more... - Date Calculators - Time Zone Converters - And more... - Generate Prime Numbers - Calculate voltage, current, or resistance - And more... - JSON Tools - CSV Tools - XML Tools - And more... https://github.com/LLmHub-dev/open-computer-use - Open Computer Use is an open-source platform that gives AI agents real computer control through browser automation, terminal access, and desktop interaction - Built for developers who want to create truly autonomous AI workflows - Unlike traditional AI assistants that only talk about tasks, Open Computer Use enables AI agents to actually perform them by: - ðŸŒ Browsing the web like a human (search, click, fill forms, extract data) - ðŸ’» Running terminal commands and managing files - ðŸ–±ï¸ Controlling desktop applications with full UI automation - ðŸ¤– Multi-agent orchestration that breaks down complex tasks - ðŸ”„ Streaming execution with real-time feedback - ðŸŽ¯ 100% open-source and self-hostable - &#34;Computer use&#34; capabilities similar to Anthropic&#39;s Claude Computer Use, but fully open-source and extensible - AI agent searching, navigating, and interacting with websites autonomously - Executing commands, managing files, and running complex workflows - Complex tasks broken down and executed by specialized agents - Human-in-the-loop control and intelligent collaboration https://github.com/hunvreus/devpush - Open-source and self-hostable alternative to Vercel, Render, Netlify, etc. - Build and deploy any app (Python, Node.js, PHP, etc.) with zero-downtime updates. - Features: real-time logs, team management, customizable environments, and domains. - Git-based deployments: Push to deploy from GitHub with zero-downtime rollouts and instant rollback. - Multi-language support: Python, Node.js, PHP, or anything that can run on Docker. - Environment management: Multiple environments with branch mapping and encrypted environment variables. - Real-time monitoring: Live and searchable build and runtime logs. - Team collaboration: Role-based access control with team invitations and permissions. - Custom domains: Support for custom domains and automatic Let&#39;s Encrypt SSL certificates. - Self-hosted and open source: Run on your own servers, MIT licensed. - Server requirements: Ubuntu 20.04&#43; or Debian 11&#43; with SSH access and sudo privileges. - Recommended DNS provider: Cloudflare. - GitHub account required for GitHub App creation. - Email provider: Resend account for login emails and invitations. - Officially supported on Ubuntu/Debian; other distros may work but are not officially supported. https://github.com/n00bvn/CanvasMCPClient - Customizable infinite canvas dashboard with integrated Model Context Protocol (MCP) server support - Open-source, self-hostable dashboard application with infinite, zoomable, and pannable canvas - Unified interface for interacting with multiple MCP servers through a flexible, widget-based system - Features: - ðŸŽ¨ Infinite Canvas: Organize workspace spatially with unlimited zoom and pan capabilities - ðŸ§© Modular Widgets: 12&#43; pre-built widgets or create custom components - ðŸ› ï¸ No-code Widget Builder: Create widgets without coding - ðŸ¤– MCP Integration: Connect to multiple MCP servers using FastMCP library - ðŸ”Œ AI-Powered: Configure multiple AI providers (OpenAI, Anthropic, Ollama, Google) - ðŸŽ­ Template System: Save and share widget and dashboard configurations - ðŸ³ Easy Deployment: One-command Docker setup or manual installation - ðŸ”’ Privacy-First: All data stays on your infrastructure, no external dependencies https://www.ultracite.ai/ - Highly opinionated, zero-configuration linter and formatter - Ultracite is a preset for Biome, designed for consistent and type-safe code without configuration - Why choose Ultracite? - Zero-config by design - Hundreds of rules for JavaScript/TypeScript optimization - Customizable when needed - Designed for humans and AI - Ensures consistent code style and quality - Reduces code review friction - Agent integration for AI workflows - Editor configuration generation - Configurable spec with zero-config Biome - MCP Support for remote linting/formatting - VS Code output panel integration - Works with popular IDEs and AI agents https://github.com/AgiFlow/aicode-toolkit - Enforce AI coding agents to follow team conventions and existing practices - Centralized, shareable location with hierarchical inheritance for team conventions - Encode best practices in YAML instead of plain-text documentation - Works across multiple AI tools (Claude Code, Cursor, Gemini CLI) https://www.reddit.com/r/LocalLLaMA/comments/1o6zg97/update_qwen3vl_cookbooks_coming_recognition/ - Qwen3-VL cookbooks coming soon, covering recognition, localization, document parsing, video understanding, and key information extraction. - Cookbooks for various capabilities: - **Omni Recognition**: Identify animals, plants, people, scenic spots, cars, merchandise, and more. - **Powerful Document Parsing**: Parse text, layout position info, and Qwen HTML format. - **Precise Object Grounding**: Supports relative position coordinates (boxes/points) for positioning and labeling. - **General OCR &amp; Key Info Extraction**: Strong text recognition in natural scenes/multiple languages; supports diverse key info extraction. - **Video Understanding**: Better video OCR, long video understanding, and video grounding. - **Mobile Agent**: Locate and think for mobile phone control. - **Computer-Use Agent**: Locate and think for controlling computers and the web. - **3D Grounding**: Accurate 3D bounding boxes for indoor/outdoor objects. - **Thinking with Images**: Uses `image_zoom_in_tool` and `search_tool` for fine-grained visual detail comprehension. - **MultiModal Coding**: Generate accurate code based on multimodal info. - **Long Document Understanding**: Rigorous semantic comprehension of ultra-long documents. - **Spatial Understanding**: See, understand, and reason about spatial information. https://github.com/thomasschafer/scooter - Interactive find-and-replace terminal UI app. - Recursively searches files in the current directory by default. https://www.reddit.com/r/mcp/comments/1oc7b90/interactive_brokers_mcp/ - Interactive Brokers MCP https://old.reddit.com/r/LocalLLaMA/comments/1obn0q7/the_innovations_in_deepseek_ocr/ - DeepSeek released a new paper called &#34;DeepSeek OCR,&#34; which is more significant than a typical OCR model. - Traditional vision LLM tokens were inefficient, often requiring more space than text tokens (e.g., 10k words â†’ 15k tokens or 30k-60k visual tokens). - DeepSeek achieved 10x better compression with vision tokens compared to text tokens (10k words â†’ 1,500 compressed visual tokens). - This aligns with human memory, where visual recall (e.g., book page layout) is often more efficient than textual recall. - Unclear how this affects LLM reasoningâ€”whether compressed visual tokens impact articulation or cognitive performance. - Potential to expand context sizes significantly, especially when combined with sparse attention techniques. - Google (Gemini) may already use similar methods, explaining its large context size and OCR efficiency, but keeps it secret. - DeepSeek open-sourced their model, allowing public exploration and experimentation. - Even with potential trade-offs (e.g., lossy attention), this could enable frontier LLMs with 10-20 million token context windows. - Practical applications: - Storing entire company documents in a prompt preamble for efficient querying. - Caching entire codebases and updating them via git diffs. - Analogy to physicist Hans Bethe, who memorized vast data for seamless problem-solving. - This approach could expand working memory capacity by 10x or more. https://github.com/hauxir/macos-live-screensaver - A macOS screensaver that plays live video streams. - Supports YouTube videos and direct HLS streams. - Also available: Android TV Live Screensaver. - Turn any live stream into your screensaver/lockscreen. https://github.com/requie/LLMSecurityGuide - Comprehensive guide to offensive and defensive security for Large Language Models and Agentic AI Systems https://github.com/youkchansim/tree-of-thought - Systematic problem-solving framework for Claude Code CLI based on Princeton NLP research - Tree of Thought (ToT) enables AI to solve complex problems through systematic exploration of solution spaces - Generates multiple solution paths at each decision point - Evaluates and compares different approaches systematically - Backtracks and explores alternatives when paths don&#39;t work - Finds optimal solutions through structured search https://github.com/huntoai/phishing-ai-agent - AI agent designed to identify vulnerable employees susceptible to phishing attacks - Uses public data sources to gather information and assess vulnerability https://github.com/ArmanShirzad/fastapi-production-template - Production-ready FastAPI template with Docker, CI/CD, observability, and one-click deployment to Render or Koyeb - UV package management for faster, more reliable builds - FastAPI with Python 3.12 https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the - OpenAI released gpt-oss-120b and gpt-oss-20b, their first open-weight models since GPT-2 in 2019. - These models can run locally with optimizations like MXFP4 quantization. - The architecture builds on the transformer design but includes several modern tweaks. - Key changes from GPT-2: - Removal of dropout (no longer needed due to single-epoch training). - Replacement of absolute positional embeddings with RoPE (Rotary Position Embedding). - Swish/SwiGLU activation functions replace GELU for computational efficiency. - Mixture-of-Experts (MoE) replaces single feed-forward modules for sparse activation. - Grouped Query Attention (GQA) replaces Multi-Head Attention (MHA) for efficiency. - Sliding window attention alternates with full-context layers to reduce compute costs. - RMSNorm replaces LayerNorm for cheaper normalization. - Comparison with Qwen3: - gpt-oss is wider (larger embedding dimensions) while Qwen3 is deeper (more transformer blocks). - gpt-oss uses fewer, larger experts (32 vs. 128 in Qwen3) but activates fewer per token (4 vs. 8). - Both use GQA, but gpt-oss adds sliding window attention. - gpt-oss includes attention bias units (rare in modern models) and attention sinks (learned per-head bias logits). - Training details: - Trained on mostly English, text-only datasets with a focus on STEM, coding, and general knowledge. - Includes supervised fine-tuning and reinforcement learning stages. - 2.1 million H100-hours for gpt-oss-120b (10x less for gpt-oss-20b). - Reasoning capabilities: - Supports adjustable reasoning effort (low/medium/high) via system prompts. - Designed for tool use, potentially reducing reliance on memorization. - MXFP4 optimization: - Enables single-GPU inference (80GB H100 for 120B model, 16GB VRAM for 20B model). - Requires RTX 50-series or newer for full efficiency (older GPUs supported with higher memory usage). - Benchmarks: - Competitive with proprietary models like GPT-5 and Qwen3 in reasoning tasks. - Not yet listed on LM Arena leaderboard; early users report high hallucination rates. - Licensing: - Apache 2.0 license (open-weight, not full open-source). - Allows commercial use and distillation into other models. - GPT-5 context: - Released shortly after gpt-oss, showing OpenAIâ€™s open models are close to proprietary performance. - Additional notes: - Attention sinks stabilize long-context scenarios without modifying input tokens. - Sliding window attention (128 tokens) is smaller than in other models (e.g., Gemmaâ€™s 1024 tokens). - No base models released (only instruction-tuned versions), unlike Qwen3. https://github.com/theaniketgiri/create-llm - CLI tool for scaffolding LLM creation and training - Create production-ready LLM training projects in seconds - Similar to create-next-app but for training custom language models https://github.com/kchander/magix-extension - AI-Powered Website Customization in Your Browser - Magix is a powerful Chrome extension that lets you modify any website using natural language - No coding required - just describe what you want, and watch as AI generates and applies the changes in real-time - Think of it as ChatGPT meets Tampermonkey - the conversational intelligence of AI combined with the power of custom scripts - ðŸŽ¨ Customize Any Site - Dark mode for sites that don&#39;t have it, remove annoying elements, add missing features - ðŸ’¬ Chat-Based Interface - Iteratively improve your modifications through conversation - ðŸ”’ Privacy-First - Uses your own API keys, no data collection - ðŸŒ Community Sharing - Discover and install modifications made by others - âš¡ Instant Results - See changes applied in real-time https://github.com/DeutscheKI/jetbrains-mini-agent - OfflineAI is a privacy-optimized LLM coding agent. - Works best with `Qwen3-Coder-30B-A3B-Instruct-UD-Q4_K_XL.gguf` on RTX 3090 or higher. - Activate by clicking in source code and pressing `Ctrl&#43;Alt&#43;Shift&#43;H` (for Help). - OfflineAI Chat window opens; type a task and start with `Ctrl&#43;Return`. - Cancel tasks with the &#34;Reset Chat History&#34; button (top right). - Agent never modifies files directly; shows diffs in the IDE. https://github.com/swannysec/lessons-from-github - A compilation of professional principles and lessons learned from nearly a decade defending the internet from baddies at GitHub - Practical Guidance for Security and Engineering Professionals https://eugeneyan.com/writing/principal/ - Different principals have different strengths: deep expertise, horizontal influence, technical leadership, or cross-org alignment. - Principals should remain hands-on, but their core role shifts to vision, design, sponsorship, and enabling others. - Principals act as part-time PMs, engineers, designers, and moreâ€”nothing is outside their scope. - More communication, influence, and cross-team collaboration are required; avoid shipping org charts to customers. - Being right isnâ€™t enoughâ€”you must convince others to act, build momentum, and secure sponsorship. - Principals often teach the org to value new ideas, even if success rates are low (e.g., 3 out of 10 pitches). - Focus on work that wonâ€™t happen without youâ€”prototype, align orgs, or define long-term vision. - Connecting teams, reusing solutions, and identifying growth opportunities can be more valuable than doing the work yourself. - Scale impact by coaching and mentoring others; set aside time for office hours or regular syncs. - Transition ownership to othersâ€”let them drive direction, even if their approach differs from yours. - Create space in meetings for others to contribute; avoid dominating discussions. - Silence in meetings can signal trustâ€”if the team is on track, step back. - In exec meetings, focus on meaningful questions and decisions only they can make. - Guard your timeâ€”avoid becoming the &#34;go-to&#34; person for every meeting or review. - If you canâ€™t justify why a project needs a principal, reconsider its priority. - Leverage organizational privilege to improve outcomes with minimal effort. - Be mindful of your influenceâ€”casual comments may be overinterpreted. - Always explain the &#34;why&#34; behind your decisions to prevent blind adherence. - Stay connected with teams through reviews, demos, or informal interactions. - Help teams see the bigger picture beyond day-to-day delivery. - Balance big-picture thinking with pragmatic, local solutions. - Decline low-quality feedback requests if you lack sufficient context. - Engage with internsâ€”early check-ins and meaningful projects can be transformative. - Remove yourself from the critical path; empower others to take ownership. - If promoted, continue what made you successfulâ€”engage with peers and define your focus. - Autonomy comes with responsibilityâ€”choose high-leverage problems, not just what you prefer. - Define your charter: owner (deep involvement), sponsor (alignment/drive), or consultant (guidance). - Build a peer networkâ€”being a principal can feel isolating. - Prioritize personal growth and well-being to avoid burnout. - Keep learningâ€”timebox stagnant projects and seek external knowledge (papers, prototypes). https://github.com/gruquilla/FinAPy - Single-stock analysis using Python and local machine learning/ AI tools (Ollama, LSTM). CC BY-NC-SA. https://github.com/relikd/Memmon - Memmon restores window positions on external monitors for Mac. - Limitations: - Restores windows in other spaces only if the space is activated. - Untested support for &#34;Displays have separate Spaces&#34; (issue #5). - Requires macOS 10.10 or newer. https://github.com/Ranteck/PyStrict-strict-python - Maximum strictness for Python projects, inspired by TypeScriptâ€™s --strict mode. - Provides a `pyproject.toml` template and tooling configuration. https://github.com/louivers/spacepigeon - SpacePigeon is a native macOS app (powered by Hammerspoon) that lets you define workspaces â€” which apps open, which desktop spaces they go to, and how windows are arranged. - Effortlessly transition between workflows. SpacePigeon instantly orchestrates your applications, windows, and displays into the perfect environment for any task with a single click or hotkey. - ðŸš€ One-Click Setup: Installs everything automatically. If you don&#39;t have Hammerspoon, SpacePigeon will download and install it for you. - ðŸŽ¨ Visual Configuration: A full native UI to manage your workspaces. No need to touch Lua code manually. - ðŸ–¥ Multi-Monitor Support: Configure spaces and app layouts for both your Main and Secondary monitors. https://github.com/devtoolcss/chrome-inspector-mcp - Provides agents with DOM Elements, CSS Rules, and Computed Style tools not available in chrome-devtools-mcp https://github.com/siddharthvaddem/openscreen - OpenScreen is a free, open-source alternative to Screen Studio for creating product demos and walkthroughs. - Simpler than Screen Studio, covering basic features without a $29/month cost. - Not a 1:1 clone; supports essential functionality for users who want control and no fees. - 100% free for personal and commercial use; modify and distribute as needed (attribution appreciated). - Features: - Record full screen or specific apps. - Manual zooms with customizable depth levels. - Adjust zoom duration and position. - Crop recordings to hide parts. - Background options: wallpapers, solid colors, gradients, or custom images. - Motion blur for smoother transitions. - Add annotations (text, arrows, images). - Trim video clips. - Export in various aspect ratios and resolutions. https://brooker.co.za/blog/2025/11/20/what-now.html - Cloudflareâ€™s November 18 outage postmortem sparked discussions about error handling, focusing on Rustâ€™s `Result` and `unwrap`. - `Result` in Rust can hold a success or error; `unwrap` extracts the success or crashes the program (similar to `assert`). - Debate on `assert` in production misses the pointâ€”error handling is a global system property, not local. - Error handling game: Decide if crashing (âœ…) or not (âŒ) is appropriate, with justifications provided. - Three principles guide error handling decisions: - **Correlated failures**: If failures are uncorrelated, crashing simplifies the system; if correlated, design to reject errors and continue. - **Higher-layer handling**: Traditional architectures handle low error rates; fine-grained (e.g., serverless) handle higher rates, making crashing more acceptable. - **Meaningful continuation**: Some systems (e.g., databases) must crash to avoid state corruption; others can use last-known-good versions. - Error handling must be designed globally from the start; local decisions are insufficient. - Blast radius reduction (e.g., cell-based architectures, shuffle sharding) limits damage from errors. - `panic` (like `unwrap`) is treated as a crash here; Rustâ€™s explicitness is better than Câ€™s silent failures. - Suggestions: Rename `unwrap` to `or_panic` or enforce justifications via lints (e.g., `clippy`). https://github.com/vijaykumarpeta/yt-comments-extractor - Powerful desktop application for extracting and filtering YouTube comments with advanced spam detection - Built for researchers, data analysts, content creators, and anyone needing clean, actionable comment data - Connects to YouTube Data API to fetch comments from any public video https://github.com/gadievron/raptor - Autonomous Offensive/Defensive Research Framework - RAPTOR: Recursive Autonomous Penetration Testing and Observation Robot - Features: - Scans code with Semgrep and CodeQL - Fuzzes binaries with AFL - Analyzes vulnerabilities using LLM reasoning - Generates proof-of-concepts - Patches vulnerabilities - FFmpeg-specific patching - OSS Forensics for GitHub investigations - Agentic Skills Engine (SecOpsAgentKit) - Structured reporting https://github.com/remorses/playwriter - Like Playwright MCP but via extension - 90% less context window - 10x more capable (full playwright API) https://github.com/breethomas/pm-coding-guardrails - Coding standards and quality gates for product managers working with AI assistants in shared codebases - PMs using AI to code face unique challenges: shipping value quickly without creating cleanup work for engineering teams https://github.com/trimstray/nginx-admins-handbook - My notes on NGINX administration basics, tips &amp; tricks, caveats, and gotchas. https://github.com/bullmeza/screen.vision - Try for free at [screen.vision](https://screen.vision) - Demo video: [Screen.Vision.Demo.mp4](https://screen.vision/demo) - **How It Works:** - Describe your goal (e.g., &#34;Set up 2FA on Google&#34; or &#34;Configure Git SSH keys&#34;) - Share screen via browserâ€™s built-in screen sharing - AI analyzes screen state using vision language models - Receive one instruction at a time (e.g., &#34;Click the blue Settings button&#34;) - Automatic progress detection â€“ Next step provided after screen changes">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-12-21T19:29:04+00:00">
    <meta property="article:modified_time" content="2025-12-21T19:29:04+00:00">
    <meta property="article:tag" content="Links">


    
      <base href="/posts/1766345343-linklist-2025-12-21/">
    
    <title>
  Link List :: 2025-12-21 Â· deskriders
</title>

    
      <link rel="canonical" href="/posts/1766345343-linklist-2025-12-21/">
    

    <link href="https://fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather:300,700%7CSource+Code+Pro:400,700" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.11.2/css/all.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />

    
      
      
      <link rel="stylesheet" href="/css/coder.min.28d751104f30c16da1aa1bb04015cbe662cacfe0d1b01af4f2240ad58580069c.css" integrity="sha256-KNdREE8wwW2hqhuwQBXL5mLKz&#43;DRsBr08iQK1YWABpw=" crossorigin="anonymous" media="screen" />
    

    

    
      
        
        
        <link rel="stylesheet" href="/css/coder-dark.min.83a2010dac9f59f943b3004cd6c4f230507ad036da635d3621401d42ec4e2835.css" integrity="sha256-g6IBDayfWflDswBM1sTyMFB60DbaY102IUAdQuxOKDU=" crossorigin="anonymous" media="screen" />
      
    

    

    

    

    <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.143.1">
  </head>

  
  
    
  
  <body class="colorscheme-auto">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      deskriders
    </a>
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="/posts/">Blog</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="/products">Products</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="/notes/">Notes</a>
          </li>
        
      
      
    </ul>
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">Link List :: 2025-12-21</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2025-12-21T19:29:04Z'>
                December 21, 2025
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              16 minutes read
            </span>
          </div>
          <div class="categories">
  <i class="fas fa-folder"></i>
    <a href="/categories/linklist/">linklist</a></div>

          <div class="tags">
  <i class="fas fa-tag"></i>
    <a href="/tags/links/">links</a></div>

        </div>
      </header>

      <div>
        <h2 id="httpswwwtheargumentmagcompyou-have-18-months"><a href="https://www.theargumentmag.com/p/you-have-18-months">https://www.theargumentmag.com/p/you-have-18-months</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> The real deadline isnâ€™t when AI outsmarts us â€” itâ€™s when we stop using our own minds.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> &#34;Time under tension&#34; in fitness (e.g., slower squats) builds more muscle; thinking benefits from a similar principle.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Deep thinking requires sitting with disconnected ideas to combine them into something new.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> AI executives claim humans have 18 months before AI surpasses us in the workforce.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> The bigger concern isnâ€™t AI taking jobs but humans degrading their own thinking abilities.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> AI is already affecting deep thinking, writing, and reading skills.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Students increasingly use AI to cheat, leading to a decline in writing and critical thinking.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Writing is thinking; outsourcing it to AI empties the mind of original thought.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Reading scores are at a 32-year low, with many students unable to focus on long texts.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Even elite college students struggle with reading full books or sustained focus.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> High schools have &#34;chunkified&#34; books to prepare for standardized tests, reducing deep reading.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Writing and reading are essential for deep symbolic thinking, a key skill in the modern economy.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> AI is the latest threat to deep thinking, following TV, the internet, and smartphones.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Literacy restructures human thought, enabling complex ideas; its decline unwires cognitive abilities.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> The skill to prioritize in the AI age: patience for long texts, holding conflicting ideas, and engaging deeply with writing.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> The author prepares their child for resilience and adaptability, emphasizing continuous learning.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> The author (who has ADD) uses AI as a tool to refine their own writing, not replace it.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> AI can be helpful if used to clarify thoughts, not to bypass thinking entirely.
</span></span></code></pre></div><h2 id="httpsgithubcomiib0011omni-tools"><a href="https://github.com/iib0011/omni-tools">https://github.com/iib0011/omni-tools</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Welcome to OmniTools, a self-hosted web app offering a variety of online tools to simplify everyday tasks.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Whether you are coding, manipulating images/videos, PDFs or crunching numbers, OmniTools has you covered.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Please don&#39;t forget to star the repo to support us.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> All files are processed entirely on the client side: nothing ever leaves your device.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> The Docker image is super lightweight at just 28MB, making it fast to deploy and easy to self-host.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Tools include:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Image Resizer
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Image Converter
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Image Editor
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Video Trimmer
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Video Reverser
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> And more...
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> PDF Splitter
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> PDF Merger
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> PDF Editor
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> And more...
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Case Converters
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> List Shuffler
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Text Formatters
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> And more...
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Date Calculators
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Time Zone Converters
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> And more...
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Generate Prime Numbers
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Calculate voltage, current, or resistance
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> And more...
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> JSON Tools
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> CSV Tools
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> XML Tools
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> And more...
</span></span></code></pre></div><h2 id="httpsgithubcomllmhub-devopen-computer-use"><a href="https://github.com/LLmHub-dev/open-computer-use">https://github.com/LLmHub-dev/open-computer-use</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Open Computer Use is an open-source platform that gives AI agents real computer control through browser automation, terminal access, and desktop interaction
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Built for developers who want to create truly autonomous AI workflows
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Unlike traditional AI assistants that only talk about tasks, Open Computer Use enables AI agents to actually perform them by:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸŒ Browsing the web like a human (search, click, fill forms, extract data)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸ’» Running terminal commands and managing files
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸ–±ï¸ Controlling desktop applications with full UI automation
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸ¤– Multi-agent orchestration that breaks down complex tasks
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸ”„ Streaming execution with real-time feedback
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸŽ¯ 100% open-source and self-hostable
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> &#34;Computer use&#34; capabilities similar to Anthropic&#39;s Claude Computer Use, but fully open-source and extensible
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> AI agent searching, navigating, and interacting with websites autonomously
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Executing commands, managing files, and running complex workflows
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Complex tasks broken down and executed by specialized agents
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Human-in-the-loop control and intelligent collaboration
</span></span></code></pre></div><h2 id="httpsgithubcomhunvreusdevpush"><a href="https://github.com/hunvreus/devpush">https://github.com/hunvreus/devpush</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Open-source and self-hostable alternative to Vercel, Render, Netlify, etc.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Build and deploy any app (Python, Node.js, PHP, etc.) with zero-downtime updates.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Features: real-time logs, team management, customizable environments, and domains.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Git-based deployments: Push to deploy from GitHub with zero-downtime rollouts and instant rollback.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Multi-language support: Python, Node.js, PHP, or anything that can run on Docker.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Environment management: Multiple environments with branch mapping and encrypted environment variables.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Real-time monitoring: Live and searchable build and runtime logs.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Team collaboration: Role-based access control with team invitations and permissions.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Custom domains: Support for custom domains and automatic Let&#39;s Encrypt SSL certificates.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Self-hosted and open source: Run on your own servers, MIT licensed.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Server requirements: Ubuntu 20.04+ or Debian 11+ with SSH access and sudo privileges.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Recommended DNS provider: Cloudflare.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> GitHub account required for GitHub App creation.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Email provider: Resend account for login emails and invitations.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Officially supported on Ubuntu/Debian; other distros may work but are not officially supported.
</span></span></code></pre></div><h2 id="httpsgithubcomn00bvncanvasmcpclient"><a href="https://github.com/n00bvn/CanvasMCPClient">https://github.com/n00bvn/CanvasMCPClient</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Customizable infinite canvas dashboard with integrated Model Context Protocol (MCP) server support
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Open-source, self-hostable dashboard application with infinite, zoomable, and pannable canvas
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Unified interface for interacting with multiple MCP servers through a flexible, widget-based system
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Features:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸŽ¨ Infinite Canvas: Organize workspace spatially with unlimited zoom and pan capabilities
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸ§© Modular Widgets: 12+ pre-built widgets or create custom components
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸ› ï¸ No-code Widget Builder: Create widgets without coding
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸ¤– MCP Integration: Connect to multiple MCP servers using FastMCP library
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸ”Œ AI-Powered: Configure multiple AI providers (OpenAI, Anthropic, Ollama, Google)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸŽ­ Template System: Save and share widget and dashboard configurations
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸ³ Easy Deployment: One-command Docker setup or manual installation
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> ðŸ”’ Privacy-First: All data stays on your infrastructure, no external dependencies
</span></span></code></pre></div><h2 id="httpswwwultraciteai"><a href="https://www.ultracite.ai/">https://www.ultracite.ai/</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Highly opinionated, zero-configuration linter and formatter
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Ultracite is a preset for Biome, designed for consistent and type-safe code without configuration
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Why choose Ultracite?
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Zero-config by design
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Hundreds of rules for JavaScript/TypeScript optimization
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Customizable when needed
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Designed for humans and AI
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Ensures consistent code style and quality
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Reduces code review friction
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Agent integration for AI workflows
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Editor configuration generation
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Configurable spec with zero-config Biome
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> MCP Support for remote linting/formatting
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> VS Code output panel integration
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Works with popular IDEs and AI agents
</span></span></code></pre></div><h2 id="httpsgithubcomagiflowaicode-toolkit"><a href="https://github.com/AgiFlow/aicode-toolkit">https://github.com/AgiFlow/aicode-toolkit</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Enforce AI coding agents to follow team conventions and existing practices
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Centralized, shareable location with hierarchical inheritance for team conventions
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Encode best practices in YAML instead of plain-text documentation
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Works across multiple AI tools (Claude Code, Cursor, Gemini CLI)
</span></span></code></pre></div><h2 id="httpswwwredditcomrlocalllamacomments1o6zg97update_qwen3vl_cookbooks_coming_recognition"><a href="https://www.reddit.com/r/LocalLLaMA/comments/1o6zg97/update_qwen3vl_cookbooks_coming_recognition/">https://www.reddit.com/r/LocalLLaMA/comments/1o6zg97/update_qwen3vl_cookbooks_coming_recognition/</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Qwen3-VL cookbooks coming soon, covering recognition, localization, document parsing, video understanding, and key information extraction.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Cookbooks for various capabilities:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Omni Recognition**: Identify animals, plants, people, scenic spots, cars, merchandise, and more.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Powerful Document Parsing**: Parse text, layout position info, and Qwen HTML format.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Precise Object Grounding**: Supports relative position coordinates (boxes/points) for positioning and labeling.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **General OCR <span style="color:#960050;background-color:#1e0010">&amp;</span> Key Info Extraction**: Strong text recognition in natural scenes/multiple languages; supports diverse key info extraction.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Video Understanding**: Better video OCR, long video understanding, and video grounding.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Mobile Agent**: Locate and think for mobile phone control.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Computer-Use Agent**: Locate and think for controlling computers and the web.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **3D Grounding**: Accurate 3D bounding boxes for indoor/outdoor objects.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Thinking with Images**: Uses <span style="color:#e6db74">`image_zoom_in_tool`</span> and <span style="color:#e6db74">`search_tool`</span> for fine-grained visual detail comprehension.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **MultiModal Coding**: Generate accurate code based on multimodal info.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Long Document Understanding**: Rigorous semantic comprehension of ultra-long documents.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Spatial Understanding**: See, understand, and reason about spatial information.
</span></span></code></pre></div><h2 id="httpsgithubcomthomasschaferscooter"><a href="https://github.com/thomasschafer/scooter">https://github.com/thomasschafer/scooter</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Interactive find-and-replace terminal UI app.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Recursively searches files in the current directory by default.
</span></span></code></pre></div><h2 id="httpswwwredditcomrmcpcomments1oc7b90interactive_brokers_mcp"><a href="https://www.reddit.com/r/mcp/comments/1oc7b90/interactive_brokers_mcp/">https://www.reddit.com/r/mcp/comments/1oc7b90/interactive_brokers_mcp/</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Interactive Brokers MCP
</span></span></code></pre></div><h2 id="httpsoldredditcomrlocalllamacomments1obn0q7the_innovations_in_deepseek_ocr"><a href="https://old.reddit.com/r/LocalLLaMA/comments/1obn0q7/the_innovations_in_deepseek_ocr/">https://old.reddit.com/r/LocalLLaMA/comments/1obn0q7/the_innovations_in_deepseek_ocr/</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> DeepSeek released a new paper called &#34;DeepSeek OCR,&#34; which is more significant than a typical OCR model.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Traditional vision LLM tokens were inefficient, often requiring more space than text tokens (e.g., 10k words â†’ 15k tokens or 30k-60k visual tokens).
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> DeepSeek achieved 10x better compression with vision tokens compared to text tokens (10k words â†’ 1,500 compressed visual tokens).
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> This aligns with human memory, where visual recall (e.g., book page layout) is often more efficient than textual recall.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Unclear how this affects LLM reasoningâ€”whether compressed visual tokens impact articulation or cognitive performance.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Potential to expand context sizes significantly, especially when combined with sparse attention techniques.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Google (Gemini) may already use similar methods, explaining its large context size and OCR efficiency, but keeps it secret.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> DeepSeek open-sourced their model, allowing public exploration and experimentation.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Even with potential trade-offs (e.g., lossy attention), this could enable frontier LLMs with 10-20 million token context windows.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Practical applications:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Storing entire company documents in a prompt preamble for efficient querying.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Caching entire codebases and updating them via git diffs.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Analogy to physicist Hans Bethe, who memorized vast data for seamless problem-solving.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> This approach could expand working memory capacity by 10x or more.
</span></span></code></pre></div><h2 id="httpsgithubcomhauxirmacos-live-screensaver"><a href="https://github.com/hauxir/macos-live-screensaver">https://github.com/hauxir/macos-live-screensaver</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> A macOS screensaver that plays live video streams.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Supports YouTube videos and direct HLS streams.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Also available: Android TV Live Screensaver.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Turn any live stream into your screensaver/lockscreen.
</span></span></code></pre></div><h2 id="httpsgithubcomrequiellmsecurityguide"><a href="https://github.com/requie/LLMSecurityGuide">https://github.com/requie/LLMSecurityGuide</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Comprehensive guide to offensive and defensive security for Large Language Models and Agentic AI Systems
</span></span></code></pre></div><h2 id="httpsgithubcomyoukchansimtree-of-thought"><a href="https://github.com/youkchansim/tree-of-thought">https://github.com/youkchansim/tree-of-thought</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Systematic problem-solving framework for Claude Code CLI based on Princeton NLP research
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Tree of Thought (ToT) enables AI to solve complex problems through systematic exploration of solution spaces
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Generates multiple solution paths at each decision point
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Evaluates and compares different approaches systematically
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Backtracks and explores alternatives when paths don&#39;t work
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Finds optimal solutions through structured search
</span></span></code></pre></div><h2 id="httpsgithubcomhuntoaiphishing-ai-agent"><a href="https://github.com/huntoai/phishing-ai-agent">https://github.com/huntoai/phishing-ai-agent</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> AI agent designed to identify vulnerable employees susceptible to phishing attacks
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Uses public data sources to gather information and assess vulnerability
</span></span></code></pre></div><h2 id="httpsgithubcomarmanshirzadfastapi-production-template"><a href="https://github.com/ArmanShirzad/fastapi-production-template">https://github.com/ArmanShirzad/fastapi-production-template</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Production-ready FastAPI template with Docker, CI/CD, observability, and one-click deployment to Render or Koyeb
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> UV package management for faster, more reliable builds
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> FastAPI with Python 3.12
</span></span></code></pre></div><h2 id="httpsmagazinesebastianraschkacompfrom-gpt-2-to-gpt-oss-analyzing-the"><a href="https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the">https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> OpenAI released gpt-oss-120b and gpt-oss-20b, their first open-weight models since GPT-2 in 2019.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> These models can run locally with optimizations like MXFP4 quantization.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> The architecture builds on the transformer design but includes several modern tweaks.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Key changes from GPT-2:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Removal of dropout (no longer needed due to single-epoch training).
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Replacement of absolute positional embeddings with RoPE (Rotary Position Embedding).
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Swish/SwiGLU activation functions replace GELU for computational efficiency.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Mixture-of-Experts (MoE) replaces single feed-forward modules for sparse activation.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Grouped Query Attention (GQA) replaces Multi-Head Attention (MHA) for efficiency.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Sliding window attention alternates with full-context layers to reduce compute costs.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> RMSNorm replaces LayerNorm for cheaper normalization.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Comparison with Qwen3:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> gpt-oss is wider (larger embedding dimensions) while Qwen3 is deeper (more transformer blocks).
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> gpt-oss uses fewer, larger experts (32 vs. 128 in Qwen3) but activates fewer per token (4 vs. 8).
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Both use GQA, but gpt-oss adds sliding window attention.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> gpt-oss includes attention bias units (rare in modern models) and attention sinks (learned per-head bias logits).
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Training details:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Trained on mostly English, text-only datasets with a focus on STEM, coding, and general knowledge.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Includes supervised fine-tuning and reinforcement learning stages.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> 2.1 million H100-hours for gpt-oss-120b (10x less for gpt-oss-20b).
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Reasoning capabilities:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Supports adjustable reasoning effort (low/medium/high) via system prompts.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Designed for tool use, potentially reducing reliance on memorization.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> MXFP4 optimization:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Enables single-GPU inference (80GB H100 for 120B model, 16GB VRAM for 20B model).
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Requires RTX 50-series or newer for full efficiency (older GPUs supported with higher memory usage).
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Benchmarks:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Competitive with proprietary models like GPT-5 and Qwen3 in reasoning tasks.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Not yet listed on LM Arena leaderboard; early users report high hallucination rates.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Licensing:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Apache 2.0 license (open-weight, not full open-source).
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Allows commercial use and distillation into other models.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> GPT-5 context:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Released shortly after gpt-oss, showing OpenAIâ€™s open models are close to proprietary performance.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Additional notes:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Attention sinks stabilize long-context scenarios without modifying input tokens.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Sliding window attention (128 tokens) is smaller than in other models (e.g., Gemmaâ€™s 1024 tokens).
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> No base models released (only instruction-tuned versions), unlike Qwen3.
</span></span></code></pre></div><h2 id="httpsgithubcomtheaniketgiricreate-llm"><a href="https://github.com/theaniketgiri/create-llm">https://github.com/theaniketgiri/create-llm</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> CLI tool for scaffolding LLM creation and training
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Create production-ready LLM training projects in seconds
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Similar to create-next-app but for training custom language models
</span></span></code></pre></div><h2 id="httpsgithubcomkchandermagix-extension"><a href="https://github.com/kchander/magix-extension">https://github.com/kchander/magix-extension</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> AI-Powered Website Customization in Your Browser
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Magix is a powerful Chrome extension that lets you modify any website using natural language
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> No coding required - just describe what you want, and watch as AI generates and applies the changes in real-time
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Think of it as ChatGPT meets Tampermonkey - the conversational intelligence of AI combined with the power of custom scripts
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> ðŸŽ¨ Customize Any Site - Dark mode for sites that don&#39;t have it, remove annoying elements, add missing features
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> ðŸ’¬ Chat-Based Interface - Iteratively improve your modifications through conversation
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> ðŸ”’ Privacy-First - Uses your own API keys, no data collection
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> ðŸŒ Community Sharing - Discover and install modifications made by others
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> âš¡ Instant Results - See changes applied in real-time
</span></span></code></pre></div><h2 id="httpsgithubcomdeutschekijetbrains-mini-agent"><a href="https://github.com/DeutscheKI/jetbrains-mini-agent">https://github.com/DeutscheKI/jetbrains-mini-agent</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> OfflineAI is a privacy-optimized LLM coding agent.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Works best with <span style="color:#e6db74">`Qwen3-Coder-30B-A3B-Instruct-UD-Q4_K_XL.gguf`</span> on RTX 3090 or higher.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Activate by clicking in source code and pressing <span style="color:#e6db74">`Ctrl+Alt+Shift+H`</span> (for Help).
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> OfflineAI Chat window opens; type a task and start with <span style="color:#e6db74">`Ctrl+Return`</span>.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Cancel tasks with the &#34;Reset Chat History&#34; button (top right).
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Agent never modifies files directly; shows diffs in the IDE.
</span></span></code></pre></div><h2 id="httpsgithubcomswannyseclessons-from-github"><a href="https://github.com/swannysec/lessons-from-github">https://github.com/swannysec/lessons-from-github</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> A compilation of professional principles and lessons learned from nearly a decade defending the internet from baddies at GitHub
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Practical Guidance for Security and Engineering Professionals
</span></span></code></pre></div><h2 id="httpseugeneyancomwritingprincipal"><a href="https://eugeneyan.com/writing/principal/">https://eugeneyan.com/writing/principal/</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Different principals have different strengths: deep expertise, horizontal influence, technical leadership, or cross-org alignment.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Principals should remain hands-on, but their core role shifts to vision, design, sponsorship, and enabling others.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Principals act as part-time PMs, engineers, designers, and moreâ€”nothing is outside their scope.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> More communication, influence, and cross-team collaboration are required; avoid shipping org charts to customers.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Being right isnâ€™t enoughâ€”you must convince others to act, build momentum, and secure sponsorship.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Principals often teach the org to value new ideas, even if success rates are low (e.g., 3 out of 10 pitches).
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Focus on work that wonâ€™t happen without youâ€”prototype, align orgs, or define long-term vision.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Connecting teams, reusing solutions, and identifying growth opportunities can be more valuable than doing the work yourself.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Scale impact by coaching and mentoring others; set aside time for office hours or regular syncs.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Transition ownership to othersâ€”let them drive direction, even if their approach differs from yours.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Create space in meetings for others to contribute; avoid dominating discussions.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Silence in meetings can signal trustâ€”if the team is on track, step back.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> In exec meetings, focus on meaningful questions and decisions only they can make.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Guard your timeâ€”avoid becoming the &#34;go-to&#34; person for every meeting or review.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> If you canâ€™t justify why a project needs a principal, reconsider its priority.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Leverage organizational privilege to improve outcomes with minimal effort.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Be mindful of your influenceâ€”casual comments may be overinterpreted.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Always explain the &#34;why&#34; behind your decisions to prevent blind adherence.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Stay connected with teams through reviews, demos, or informal interactions.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Help teams see the bigger picture beyond day-to-day delivery.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Balance big-picture thinking with pragmatic, local solutions.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Decline low-quality feedback requests if you lack sufficient context.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Engage with internsâ€”early check-ins and meaningful projects can be transformative.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Remove yourself from the critical path; empower others to take ownership.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> If promoted, continue what made you successfulâ€”engage with peers and define your focus.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Autonomy comes with responsibilityâ€”choose high-leverage problems, not just what you prefer.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Define your charter: owner (deep involvement), sponsor (alignment/drive), or consultant (guidance).
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Build a peer networkâ€”being a principal can feel isolating.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Prioritize personal growth and well-being to avoid burnout.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Keep learningâ€”timebox stagnant projects and seek external knowledge (papers, prototypes).
</span></span></code></pre></div><h2 id="httpsgithubcomgruquillafinapy"><a href="https://github.com/gruquilla/FinAPy">https://github.com/gruquilla/FinAPy</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Single-stock analysis using Python and local machine learning/ AI tools (Ollama, LSTM). CC BY-NC-SA.
</span></span></code></pre></div><h2 id="httpsgithubcomrelikdmemmon"><a href="https://github.com/relikd/Memmon">https://github.com/relikd/Memmon</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Memmon restores window positions on external monitors for Mac.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Limitations:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Restores windows in other spaces only if the space is activated.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Untested support for &#34;Displays have separate Spaces&#34; (issue #5).
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Requires macOS 10.10 or newer.
</span></span></code></pre></div><h2 id="httpsgithubcomranteckpystrict-strict-python"><a href="https://github.com/Ranteck/PyStrict-strict-python">https://github.com/Ranteck/PyStrict-strict-python</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Maximum strictness for Python projects, inspired by TypeScriptâ€™s --strict mode.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Provides a <span style="color:#e6db74">`pyproject.toml`</span> template and tooling configuration.
</span></span></code></pre></div><h2 id="httpsgithubcomlouiversspacepigeon"><a href="https://github.com/louivers/spacepigeon">https://github.com/louivers/spacepigeon</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> SpacePigeon is a native macOS app (powered by Hammerspoon) that lets you define workspaces â€” which apps open, which desktop spaces they go to, and how windows are arranged.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Effortlessly transition between workflows. SpacePigeon instantly orchestrates your applications, windows, and displays into the perfect environment for any task with a single click or hotkey.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> ðŸš€ One-Click Setup: Installs everything automatically. If you don&#39;t have Hammerspoon, SpacePigeon will download and install it for you.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> ðŸŽ¨ Visual Configuration: A full native UI to manage your workspaces. No need to touch Lua code manually.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> ðŸ–¥ Multi-Monitor Support: Configure spaces and app layouts for both your Main and Secondary monitors.
</span></span></code></pre></div><h2 id="httpsgithubcomdevtoolcsschrome-inspector-mcp"><a href="https://github.com/devtoolcss/chrome-inspector-mcp">https://github.com/devtoolcss/chrome-inspector-mcp</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Provides agents with DOM Elements, CSS Rules, and Computed Style tools not available in chrome-devtools-mcp
</span></span></code></pre></div><h2 id="httpsgithubcomsiddharthvaddemopenscreen"><a href="https://github.com/siddharthvaddem/openscreen">https://github.com/siddharthvaddem/openscreen</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> OpenScreen is a free, open-source alternative to Screen Studio for creating product demos and walkthroughs.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Simpler than Screen Studio, covering basic features without a $29/month cost.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Not a 1:1 clone; supports essential functionality for users who want control and no fees.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> 100% free for personal and commercial use; modify and distribute as needed (attribution appreciated).
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Features:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Record full screen or specific apps.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Manual zooms with customizable depth levels.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Adjust zoom duration and position.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Crop recordings to hide parts.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Background options: wallpapers, solid colors, gradients, or custom images.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Motion blur for smoother transitions.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Add annotations (text, arrows, images).
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Trim video clips.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Export in various aspect ratios and resolutions.
</span></span></code></pre></div><h2 id="httpsbrookercozablog20251120what-nowhtml"><a href="https://brooker.co.za/blog/2025/11/20/what-now.html">https://brooker.co.za/blog/2025/11/20/what-now.html</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Cloudflareâ€™s November 18 outage postmortem sparked discussions about error handling, focusing on Rustâ€™s <span style="color:#e6db74">`Result`</span> and <span style="color:#e6db74">`unwrap`</span>.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> <span style="color:#e6db74">`Result`</span> in Rust can hold a success or error; <span style="color:#e6db74">`unwrap`</span> extracts the success or crashes the program (similar to <span style="color:#e6db74">`assert`</span>).
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Debate on <span style="color:#e6db74">`assert`</span> in production misses the pointâ€”error handling is a global system property, not local.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Error handling game: Decide if crashing (âœ…) or not (âŒ) is appropriate, with justifications provided.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Three principles guide error handling decisions:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Correlated failures**: If failures are uncorrelated, crashing simplifies the system; if correlated, design to reject errors and continue.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Higher-layer handling**: Traditional architectures handle low error rates; fine-grained (e.g., serverless) handle higher rates, making crashing more acceptable.
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> **Meaningful continuation**: Some systems (e.g., databases) must crash to avoid state corruption; others can use last-known-good versions.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Error handling must be designed globally from the start; local decisions are insufficient.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Blast radius reduction (e.g., cell-based architectures, shuffle sharding) limits damage from errors.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> <span style="color:#e6db74">`panic`</span> (like <span style="color:#e6db74">`unwrap`</span>) is treated as a crash here; Rustâ€™s explicitness is better than Câ€™s silent failures.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Suggestions: Rename <span style="color:#e6db74">`unwrap`</span> to <span style="color:#e6db74">`or_panic`</span> or enforce justifications via lints (e.g., <span style="color:#e6db74">`clippy`</span>).
</span></span></code></pre></div><h2 id="httpsgithubcomvijaykumarpetayt-comments-extractor"><a href="https://github.com/vijaykumarpeta/yt-comments-extractor">https://github.com/vijaykumarpeta/yt-comments-extractor</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Powerful desktop application for extracting and filtering YouTube comments with advanced spam detection
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Built for researchers, data analysts, content creators, and anyone needing clean, actionable comment data
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Connects to YouTube Data API to fetch comments from any public video
</span></span></code></pre></div><h2 id="httpsgithubcomgadievronraptor"><a href="https://github.com/gadievron/raptor">https://github.com/gadievron/raptor</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Autonomous Offensive/Defensive Research Framework
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> RAPTOR: Recursive Autonomous Penetration Testing and Observation Robot
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Features:
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Scans code with Semgrep and CodeQL
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Fuzzes binaries with AFL
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Analyzes vulnerabilities using LLM reasoning
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Generates proof-of-concepts
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Patches vulnerabilities
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> FFmpeg-specific patching
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> OSS Forensics for GitHub investigations
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Agentic Skills Engine (SecOpsAgentKit)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Structured reporting
</span></span></code></pre></div><h2 id="httpsgithubcomremorsesplaywriter"><a href="https://github.com/remorses/playwriter">https://github.com/remorses/playwriter</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Like Playwright MCP but via extension
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> 90% less context window
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> 10x more capable (full playwright API)
</span></span></code></pre></div><h2 id="httpsgithubcombreethomaspm-coding-guardrails"><a href="https://github.com/breethomas/pm-coding-guardrails">https://github.com/breethomas/pm-coding-guardrails</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Coding standards and quality gates for product managers working with AI assistants in shared codebases
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> PMs using AI to code face unique challenges: shipping value quickly without creating cleanup work for engineering teams
</span></span></code></pre></div><h2 id="httpsgithubcomtrimstraynginx-admins-handbook"><a href="https://github.com/trimstray/nginx-admins-handbook">https://github.com/trimstray/nginx-admins-handbook</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> My notes on NGINX administration basics, tips <span style="color:#960050;background-color:#1e0010">&amp;</span> tricks, caveats, and gotchas.
</span></span></code></pre></div><h2 id="httpsgithubcombullmezascreenvision"><a href="https://github.com/bullmeza/screen.vision">https://github.com/bullmeza/screen.vision</a></h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Try for free at [<span style="color:#f92672">screen.vision</span>](<span style="color:#a6e22e">https://screen.vision</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> Demo video: [<span style="color:#f92672">Screen.Vision.Demo.mp4</span>](<span style="color:#a6e22e">https://screen.vision/demo</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">-</span> **How It Works:**
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Describe your goal (e.g., &#34;Set up 2FA on Google&#34; or &#34;Configure Git SSH keys&#34;)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Share screen via browserâ€™s built-in screen sharing
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> AI analyzes screen state using vision language models
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Receive one instruction at a time (e.g., &#34;Click the blue Settings button&#34;)
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">-</span> Automatic progress detection â€“ Next step provided after screen changes
</span></span></code></pre></div>
      </div>

      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    
    
      
        Â© 2019 - 2025
      
       Deskriders.dev 
    
    
       Â· 
      Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
    
  </section>
</footer>

    </main>

    

  </body>

</html>
